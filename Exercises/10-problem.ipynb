{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.9.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.5 64-bit ('ml': conda)"
    },
    "interpreter": {
      "hash": "7f4c6cd4773fd23e00866842a2acbb96ec8acddd4013a030ba73f204974c02c6"
    },
    "colab": {
      "name": "10-problem.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-M0BqxbMIXd-"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaocarvoli/Machine-Learning/blob/main/Exercises/10_problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F34TYV8m_PIv"
      },
      "source": [
        "# `10 - Problem`\n",
        "## In this problem our goal is to apply advanced tree-based models, boosting techniques and make a introduction to the artificial neural networks \n",
        "\n",
        "### The dataset that we'll use is [Pima Indians Diabetes Database](https://data.world/data-society/pima-indians-diabetes-database)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjXENrzl_PI0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "import xgboost as xgb\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gTJTEko_PI1"
      },
      "source": [
        "## `Data import`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "YxNvh78r_PI2",
        "outputId": "1f798c35-21b4-4dae-884d-0af75f533a08"
      },
      "source": [
        "filename = '/content/drive/MyDrive/data-sets/diabetes/diabetes.csv'\n",
        "df = pd.read_csv(filename)\n",
        "df"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies  Glucose  ...  Age  Outcome\n",
              "0              6      148  ...   50        1\n",
              "1              1       85  ...   31        0\n",
              "2              8      183  ...   32        1\n",
              "3              1       89  ...   21        0\n",
              "4              0      137  ...   33        1\n",
              "..           ...      ...  ...  ...      ...\n",
              "763           10      101  ...   63        0\n",
              "764            2      122  ...   27        0\n",
              "765            5      121  ...   30        0\n",
              "766            1      126  ...   47        1\n",
              "767            1       93  ...   23        0\n",
              "\n",
              "[768 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mGRBN2K_PI3"
      },
      "source": [
        "# 2 - Preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7jUmZPG_PI4",
        "outputId": "c0fd57b1-c07e-4fed-e803-f419f03dcb54"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh35FV4F_PI4",
        "outputId": "9b73578d-e5bb-46c7-eb1d-7bde8a8127f9"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                 0\n",
              "Glucose                     0\n",
              "BloodPressure               0\n",
              "SkinThickness               0\n",
              "Insulin                     0\n",
              "BMI                         0\n",
              "DiabetesPedigreeFunction    0\n",
              "Age                         0\n",
              "Outcome                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0HLwrmo_PI5"
      },
      "source": [
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "T4gSvHnr_PI6",
        "outputId": "fcac6530-53d5-4a08-ffe2-3168a1455527"
      },
      "source": [
        "X"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  ...   BMI  DiabetesPedigreeFunction  Age\n",
              "0              6      148             72  ...  33.6                     0.627   50\n",
              "1              1       85             66  ...  26.6                     0.351   31\n",
              "2              8      183             64  ...  23.3                     0.672   32\n",
              "3              1       89             66  ...  28.1                     0.167   21\n",
              "4              0      137             40  ...  43.1                     2.288   33\n",
              "..           ...      ...            ...  ...   ...                       ...  ...\n",
              "763           10      101             76  ...  32.9                     0.171   63\n",
              "764            2      122             70  ...  36.8                     0.340   27\n",
              "765            5      121             72  ...  26.2                     0.245   30\n",
              "766            1      126             60  ...  30.1                     0.349   47\n",
              "767            1       93             70  ...  30.4                     0.315   23\n",
              "\n",
              "[768 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJhN6O5I_PI6",
        "outputId": "386da3c5-603b-4a3c-9ec4-c5c41db3849f"
      },
      "source": [
        "y"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      0\n",
              "2      1\n",
              "3      0\n",
              "4      1\n",
              "      ..\n",
              "763    0\n",
              "764    0\n",
              "765    0\n",
              "766    1\n",
              "767    0\n",
              "Name: Outcome, Length: 768, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57gZPX8s_PI7"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=32, stratify = y)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Ff8lTJWn_PI7",
        "outputId": "5af9647b-5ca5-43e1-b7e4-9697d4db51ab"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>4</td>\n",
              "      <td>146</td>\n",
              "      <td>85</td>\n",
              "      <td>27</td>\n",
              "      <td>100</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0.189</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>5</td>\n",
              "      <td>96</td>\n",
              "      <td>74</td>\n",
              "      <td>18</td>\n",
              "      <td>67</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.997</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>6</td>\n",
              "      <td>107</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.727</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>1</td>\n",
              "      <td>112</td>\n",
              "      <td>72</td>\n",
              "      <td>30</td>\n",
              "      <td>176</td>\n",
              "      <td>34.4</td>\n",
              "      <td>0.528</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>9</td>\n",
              "      <td>102</td>\n",
              "      <td>76</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.665</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44.2</td>\n",
              "      <td>0.630</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>6</td>\n",
              "      <td>166</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.304</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>17</td>\n",
              "      <td>163</td>\n",
              "      <td>72</td>\n",
              "      <td>41</td>\n",
              "      <td>114</td>\n",
              "      <td>40.9</td>\n",
              "      <td>0.817</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>0</td>\n",
              "      <td>167</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32.3</td>\n",
              "      <td>0.839</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>2</td>\n",
              "      <td>134</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0.542</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>537 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  ...   BMI  DiabetesPedigreeFunction  Age\n",
              "69             4      146             85  ...  28.9                     0.189   27\n",
              "265            5       96             74  ...  33.6                     0.997   43\n",
              "439            6      107             88  ...  36.8                     0.727   31\n",
              "411            1      112             72  ...  34.4                     0.528   25\n",
              "37             9      102             76  ...  32.9                     0.665   46\n",
              "..           ...      ...            ...  ...   ...                       ...  ...\n",
              "484            0      145              0  ...  44.2                     0.630   31\n",
              "495            6      166             74  ...  26.6                     0.304   66\n",
              "159           17      163             72  ...  40.9                     0.817   47\n",
              "300            0      167              0  ...  32.3                     0.839   30\n",
              "451            2      134             70  ...  28.9                     0.542   23\n",
              "\n",
              "[537 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qySRizoo_PI8",
        "outputId": "f8cb5ff2-b04a-4992-c8e3-e97d792056aa"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69     0\n",
              "265    0\n",
              "439    0\n",
              "411    0\n",
              "37     1\n",
              "      ..\n",
              "484    1\n",
              "495    0\n",
              "159    1\n",
              "300    1\n",
              "451    1\n",
              "Name: Outcome, Length: 537, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlMpkh-I_PI8"
      },
      "source": [
        "# 3 - Algorithms:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks8vo2yi_PI9"
      },
      "source": [
        "## `Random Forest`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "id": "3PEG3XYY_PI9",
        "outputId": "df8f1e0c-fd0c-472d-f4fa-0bdabc4206ca"
      },
      "source": [
        "parameters = {\n",
        "  'max_depth':[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
        "  'criterion':['gini','entropy'],\n",
        "  'max_features':['auto', 'sqrt', 'log2'],\n",
        "  'n_jobs':[-1],\n",
        "  'random_state': [42],\n",
        "  'class_weight': ['balanced', 'balanced_subsample'],\n",
        "  'min_samples_split':[0.125,0.25,0.5,1,2,3,4,6,10]\n",
        "}\n",
        "\n",
        "grid_random = GridSearchCV(estimator = RandomForestClassifier(), param_grid = parameters, scoring = 'f1', cv = 5)\n",
        "grid_random.fit(X_train,y_train)\n",
        "pd.DataFrame(grid_random.cv_results_)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_class_weight</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_max_features</th>\n",
              "      <th>param_min_samples_split</th>\n",
              "      <th>param_n_jobs</th>\n",
              "      <th>param_random_state</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.408763</td>\n",
              "      <td>0.351844</td>\n",
              "      <td>0.104113</td>\n",
              "      <td>0.000410</td>\n",
              "      <td>balanced</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>auto</td>\n",
              "      <td>0.125</td>\n",
              "      <td>-1</td>\n",
              "      <td>42</td>\n",
              "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
              "      <td>0.680851</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.617284</td>\n",
              "      <td>0.541176</td>\n",
              "      <td>0.634146</td>\n",
              "      <td>0.648538</td>\n",
              "      <td>0.075261</td>\n",
              "      <td>220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.223552</td>\n",
              "      <td>0.007584</td>\n",
              "      <td>0.103720</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>balanced</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>auto</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-1</td>\n",
              "      <td>42</td>\n",
              "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.716049</td>\n",
              "      <td>0.607595</td>\n",
              "      <td>0.581395</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.644574</td>\n",
              "      <td>0.046902</td>\n",
              "      <td>297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.217967</td>\n",
              "      <td>0.010426</td>\n",
              "      <td>0.104320</td>\n",
              "      <td>0.000934</td>\n",
              "      <td>balanced</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>auto</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-1</td>\n",
              "      <td>42</td>\n",
              "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
              "      <td>0.711111</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.613333</td>\n",
              "      <td>0.611765</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.660575</td>\n",
              "      <td>0.041856</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.686703</td>\n",
              "      <td>0.301620</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>balanced</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>auto</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>42</td>\n",
              "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.405704</td>\n",
              "      <td>0.340618</td>\n",
              "      <td>0.103907</td>\n",
              "      <td>0.000392</td>\n",
              "      <td>balanced</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>auto</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>42</td>\n",
              "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
              "      <td>0.632911</td>\n",
              "      <td>0.757576</td>\n",
              "      <td>0.507463</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>0.477612</td>\n",
              "      <td>0.580995</td>\n",
              "      <td>0.102598</td>\n",
              "      <td>850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1183</th>\n",
              "      <td>0.518723</td>\n",
              "      <td>0.421881</td>\n",
              "      <td>0.103936</td>\n",
              "      <td>0.000426</td>\n",
              "      <td>balanced_subsample</td>\n",
              "      <td>entropy</td>\n",
              "      <td>None</td>\n",
              "      <td>log2</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>42</td>\n",
              "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.567164</td>\n",
              "      <td>0.451613</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.585877</td>\n",
              "      <td>0.119006</td>\n",
              "      <td>798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1184</th>\n",
              "      <td>0.309988</td>\n",
              "      <td>0.006386</td>\n",
              "      <td>0.104015</td>\n",
              "      <td>0.000702</td>\n",
              "      <td>balanced_subsample</td>\n",
              "      <td>entropy</td>\n",
              "      <td>None</td>\n",
              "      <td>log2</td>\n",
              "      <td>3</td>\n",
              "      <td>-1</td>\n",
              "      <td>42</td>\n",
              "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
              "      <td>0.643678</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.539683</td>\n",
              "      <td>0.476190</td>\n",
              "      <td>0.569615</td>\n",
              "      <td>0.082577</td>\n",
              "      <td>919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1185</th>\n",
              "      <td>0.305913</td>\n",
              "      <td>0.010042</td>\n",
              "      <td>0.103624</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>balanced_subsample</td>\n",
              "      <td>entropy</td>\n",
              "      <td>None</td>\n",
              "      <td>log2</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>42</td>\n",
              "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
              "      <td>0.681319</td>\n",
              "      <td>0.738462</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.507463</td>\n",
              "      <td>0.537313</td>\n",
              "      <td>0.607197</td>\n",
              "      <td>0.088130</td>\n",
              "      <td>674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1186</th>\n",
              "      <td>0.304508</td>\n",
              "      <td>0.007228</td>\n",
              "      <td>0.103719</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>balanced_subsample</td>\n",
              "      <td>entropy</td>\n",
              "      <td>None</td>\n",
              "      <td>log2</td>\n",
              "      <td>6</td>\n",
              "      <td>-1</td>\n",
              "      <td>42</td>\n",
              "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.492308</td>\n",
              "      <td>0.619472</td>\n",
              "      <td>0.078062</td>\n",
              "      <td>555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1187</th>\n",
              "      <td>0.303074</td>\n",
              "      <td>0.010788</td>\n",
              "      <td>0.103709</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>balanced_subsample</td>\n",
              "      <td>entropy</td>\n",
              "      <td>None</td>\n",
              "      <td>log2</td>\n",
              "      <td>10</td>\n",
              "      <td>-1</td>\n",
              "      <td>42</td>\n",
              "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
              "      <td>0.688889</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.550725</td>\n",
              "      <td>0.613333</td>\n",
              "      <td>0.535211</td>\n",
              "      <td>0.627632</td>\n",
              "      <td>0.081716</td>\n",
              "      <td>478</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1188 rows Ã— 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0          0.408763      0.351844  ...        0.075261              220\n",
              "1          0.223552      0.007584  ...        0.046902              297\n",
              "2          0.217967      0.010426  ...        0.041856               67\n",
              "3          0.686703      0.301620  ...             NaN             1090\n",
              "4          0.405704      0.340618  ...        0.102598              850\n",
              "...             ...           ...  ...             ...              ...\n",
              "1183       0.518723      0.421881  ...        0.119006              798\n",
              "1184       0.309988      0.006386  ...        0.082577              919\n",
              "1185       0.305913      0.010042  ...        0.088130              674\n",
              "1186       0.304508      0.007228  ...        0.078062              555\n",
              "1187       0.303074      0.010788  ...        0.081716              478\n",
              "\n",
              "[1188 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UUAjtnvD7zj",
        "outputId": "a71e8a75-7705-4a9e-a253-ddcd5e4e6858"
      },
      "source": [
        "grid_random.best_params_"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class_weight': 'balanced_subsample',\n",
              " 'criterion': 'entropy',\n",
              " 'max_depth': 20,\n",
              " 'max_features': 'auto',\n",
              " 'min_samples_split': 0.125,\n",
              " 'n_jobs': -1,\n",
              " 'random_state': 42}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96MRcigPEc2o",
        "outputId": "0db93621-c0da-4191-d5ae-65fe02b67998"
      },
      "source": [
        "grid_random.best_score_"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6782310542198688"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZYMVPV0RBWc"
      },
      "source": [
        "### _Aplying the best params in model_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE_GusvXFovg",
        "outputId": "ccbe6bec-eea4-4842-c208-ddc395309d11"
      },
      "source": [
        "model_random_forest = RandomForestClassifier(\n",
        " class_weight = 'balanced_subsample',\n",
        " criterion = 'entropy',\n",
        " max_depth = 20,\n",
        " max_features = 'auto',\n",
        " min_samples_split = 0.125,\n",
        " n_jobs = -1,\n",
        " random_state = 42\n",
        ")\n",
        "model_random_forest.fit(X_train, y_train)\n",
        "random_pred_train = model_random_forest.predict(X_train)\n",
        "random_pred_test = model_random_forest.predict(X_test)\n",
        "print(f'The f1_score of train is {np.round(f1_score(y_train,random_pred_train)*100,2)}% and the f1_score of test is {np.round(f1_score(y_test,random_pred_test)*100,2)}%')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f1_score of train is 76.37% and the f1_score of test is 70.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiaWUysZDz5N"
      },
      "source": [
        "results = {'algorithm':[], 'train score':[], 'test score':[]}\n",
        "results['algorithm'].append('Random Forest')\n",
        "results['train score'].append(np.round(f1_score(y_train,random_pred_train)*100,2))\n",
        "results['test score'].append(np.round(f1_score(y_test,random_pred_test)*100,2))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M0BqxbMIXd-"
      },
      "source": [
        "#### _The cross validation mades the result works worse_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9KEspq_HsOe"
      },
      "source": [
        "## `Gradient Bosting:`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEWq_daTHyds",
        "outputId": "2a66869c-4b03-4574-ef0d-427112c98fb3"
      },
      "source": [
        "parameters_grad = {\n",
        "  'loss':['deviance'],\n",
        "  'random_state': [42],\n",
        "  'max_features':['auto', 'sqrt', 'log2'],\n",
        "  'learning_rate':[0.001,0.01,0.1,1],\n",
        "  'max_depth':[10, 20, 30, 40, 80, 90, 100, None],\n",
        "  'max_features':['auto', 'sqrt', 'log2'],\n",
        "  'random_state': [42],\n",
        "  'min_samples_split':[0.125,0.25,0.5,1,2,3,4,6,10],\n",
        "  'loss' :['deviance', 'exponential']\n",
        "}\n",
        "\n",
        "grid_gradB = GridSearchCV(estimator = GradientBoostingClassifier(), param_grid = parameters_grad, scoring = 'f1', cv = 5)\n",
        "grid_gradB.fit(X_train,y_train)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n",
              "                                                  criterion='friedman_mse',\n",
              "                                                  init=None, learning_rate=0.1,\n",
              "                                                  loss='deviance', max_depth=3,\n",
              "                                                  max_features=None,\n",
              "                                                  max_leaf_nodes=None,\n",
              "                                                  min_impurity_decrease=0.0,\n",
              "                                                  min_impurity_split=None,\n",
              "                                                  min_samples_leaf=1,\n",
              "                                                  min_samples_split=2,\n",
              "                                                  min_weight_fraction_leaf=0.0,\n",
              "                                                  n_estimators=100,\n",
              "                                                  n_iter_no_c...\n",
              "                                                  verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'learning_rate': [0.001, 0.01, 0.1, 1],\n",
              "                         'loss': ['deviance', 'exponential'],\n",
              "                         'max_depth': [10, 20, 30, 40, 80, 90, 100, None],\n",
              "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
              "                         'min_samples_split': [0.125, 0.25, 0.5, 1, 2, 3, 4, 6,\n",
              "                                               10],\n",
              "                         'random_state': [42]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='f1', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "rFnysFrmWeKW",
        "outputId": "03629c3c-66a0-4da5-bb5a-3fb852c32c62"
      },
      "source": [
        "pd.DataFrame(grid_gradB.cv_results_)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_learning_rate</th>\n",
              "      <th>param_loss</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_max_features</th>\n",
              "      <th>param_min_samples_split</th>\n",
              "      <th>param_random_state</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.205204</td>\n",
              "      <td>0.006882</td>\n",
              "      <td>0.002545</td>\n",
              "      <td>0.000135</td>\n",
              "      <td>0.001</td>\n",
              "      <td>deviance</td>\n",
              "      <td>10</td>\n",
              "      <td>auto</td>\n",
              "      <td>0.125</td>\n",
              "      <td>42</td>\n",
              "      <td>{'learning_rate': 0.001, 'loss': 'deviance', '...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.140603</td>\n",
              "      <td>0.009716</td>\n",
              "      <td>0.002391</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>0.001</td>\n",
              "      <td>deviance</td>\n",
              "      <td>10</td>\n",
              "      <td>auto</td>\n",
              "      <td>0.25</td>\n",
              "      <td>42</td>\n",
              "      <td>{'learning_rate': 0.001, 'loss': 'deviance', '...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.085283</td>\n",
              "      <td>0.004835</td>\n",
              "      <td>0.002613</td>\n",
              "      <td>0.000663</td>\n",
              "      <td>0.001</td>\n",
              "      <td>deviance</td>\n",
              "      <td>10</td>\n",
              "      <td>auto</td>\n",
              "      <td>0.5</td>\n",
              "      <td>42</td>\n",
              "      <td>{'learning_rate': 0.001, 'loss': 'deviance', '...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.003849</td>\n",
              "      <td>0.000661</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>deviance</td>\n",
              "      <td>10</td>\n",
              "      <td>auto</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>{'learning_rate': 0.001, 'loss': 'deviance', '...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.391552</td>\n",
              "      <td>0.034271</td>\n",
              "      <td>0.002710</td>\n",
              "      <td>0.000103</td>\n",
              "      <td>0.001</td>\n",
              "      <td>deviance</td>\n",
              "      <td>10</td>\n",
              "      <td>auto</td>\n",
              "      <td>2</td>\n",
              "      <td>42</td>\n",
              "      <td>{'learning_rate': 0.001, 'loss': 'deviance', '...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1723</th>\n",
              "      <td>0.065572</td>\n",
              "      <td>0.001323</td>\n",
              "      <td>0.002173</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>1</td>\n",
              "      <td>exponential</td>\n",
              "      <td>None</td>\n",
              "      <td>log2</td>\n",
              "      <td>2</td>\n",
              "      <td>42</td>\n",
              "      <td>{'learning_rate': 1, 'loss': 'exponential', 'm...</td>\n",
              "      <td>0.635294</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.567568</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>0.584615</td>\n",
              "      <td>0.574938</td>\n",
              "      <td>0.036926</td>\n",
              "      <td>331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1724</th>\n",
              "      <td>0.076487</td>\n",
              "      <td>0.001108</td>\n",
              "      <td>0.002196</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>1</td>\n",
              "      <td>exponential</td>\n",
              "      <td>None</td>\n",
              "      <td>log2</td>\n",
              "      <td>3</td>\n",
              "      <td>42</td>\n",
              "      <td>{'learning_rate': 1, 'loss': 'exponential', 'm...</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.586207</td>\n",
              "      <td>0.575342</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.602740</td>\n",
              "      <td>0.573232</td>\n",
              "      <td>0.045487</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1725</th>\n",
              "      <td>0.082135</td>\n",
              "      <td>0.002242</td>\n",
              "      <td>0.002174</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>1</td>\n",
              "      <td>exponential</td>\n",
              "      <td>None</td>\n",
              "      <td>log2</td>\n",
              "      <td>4</td>\n",
              "      <td>42</td>\n",
              "      <td>{'learning_rate': 1, 'loss': 'exponential', 'm...</td>\n",
              "      <td>0.597701</td>\n",
              "      <td>0.638889</td>\n",
              "      <td>0.602740</td>\n",
              "      <td>0.563380</td>\n",
              "      <td>0.537313</td>\n",
              "      <td>0.588005</td>\n",
              "      <td>0.034861</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1726</th>\n",
              "      <td>0.083881</td>\n",
              "      <td>0.001596</td>\n",
              "      <td>0.002212</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>1</td>\n",
              "      <td>exponential</td>\n",
              "      <td>None</td>\n",
              "      <td>log2</td>\n",
              "      <td>6</td>\n",
              "      <td>42</td>\n",
              "      <td>{'learning_rate': 1, 'loss': 'exponential', 'm...</td>\n",
              "      <td>0.543210</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.515152</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.563380</td>\n",
              "      <td>0.575329</td>\n",
              "      <td>0.051585</td>\n",
              "      <td>313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1727</th>\n",
              "      <td>0.084721</td>\n",
              "      <td>0.004318</td>\n",
              "      <td>0.002522</td>\n",
              "      <td>0.000375</td>\n",
              "      <td>1</td>\n",
              "      <td>exponential</td>\n",
              "      <td>None</td>\n",
              "      <td>log2</td>\n",
              "      <td>10</td>\n",
              "      <td>42</td>\n",
              "      <td>{'learning_rate': 1, 'loss': 'exponential', 'm...</td>\n",
              "      <td>0.635294</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.602740</td>\n",
              "      <td>0.516129</td>\n",
              "      <td>0.591549</td>\n",
              "      <td>0.602476</td>\n",
              "      <td>0.050543</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1728 rows Ã— 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0          0.205204      0.006882  ...        0.000000             1153\n",
              "1          0.140603      0.009716  ...        0.000000             1153\n",
              "2          0.085283      0.004835  ...        0.000000             1153\n",
              "3          0.003849      0.000661  ...             NaN             1601\n",
              "4          0.391552      0.034271  ...        0.000000             1153\n",
              "...             ...           ...  ...             ...              ...\n",
              "1723       0.065572      0.001323  ...        0.036926              331\n",
              "1724       0.076487      0.001108  ...        0.045487              354\n",
              "1725       0.082135      0.002242  ...        0.034861              192\n",
              "1726       0.083881      0.001596  ...        0.051585              313\n",
              "1727       0.084721      0.004318  ...        0.050543               92\n",
              "\n",
              "[1728 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B78XZD48WsCr",
        "outputId": "c29f01c9-2d20-4777-9afd-211ee433312c"
      },
      "source": [
        "grid_gradB.best_params_"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 1,\n",
              " 'loss': 'deviance',\n",
              " 'max_depth': 10,\n",
              " 'max_features': 'sqrt',\n",
              " 'min_samples_split': 10,\n",
              " 'random_state': 42}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G9ExZyPWpPs",
        "outputId": "b269d034-3a80-4141-db11-f8f64abb73fa"
      },
      "source": [
        "grid_gradB.best_score_"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6286738678386813"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIPjCEqXWx9M"
      },
      "source": [
        "### _Aplying the best params in model_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC4OwvPdWygf",
        "outputId": "cad94810-329f-49de-ca6d-aa9d422789d0"
      },
      "source": [
        "model_gradient = GradientBoostingClassifier(\n",
        "  learning_rate = 1,\n",
        "  loss = 'deviance',\n",
        "  max_depth = 10,\n",
        "  max_features = 'sqrt',\n",
        "  min_samples_split = 10,\n",
        "  random_state = 42\n",
        ")\n",
        "\n",
        "model_gradient.fit(X_train, y_train)\n",
        "model_gradient_train = model_gradient.predict(X_train)\n",
        "model_gradient_test = model_gradient.predict(X_test)\n",
        "print(f'The f1_score of train is {np.round(f1_score(y_train,model_gradient_train)*100)}% and the f1_score of test is {np.round(f1_score(y_test,model_gradient_test)*100,2)}%')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f1_score of train is 100.0% and the f1_score of test is 62.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKDKTvNgEVO3"
      },
      "source": [
        "results['algorithm'].append('Gradient Bosting')\n",
        "results['train score'].append(np.round(f1_score(y_train,model_gradient_train)*100))\n",
        "results['test score'].append(np.round(f1_score(y_test,model_gradient_test)*100,2))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQv2G2njaRrq"
      },
      "source": [
        "# Now We'll apply Gradient Bosting versions that was optimazed like: XGBoost ,LightGBM and CatBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB9ZzNx1cfSO"
      },
      "source": [
        "## `XGBoosting`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "JVp5hu9CPEq-",
        "outputId": "27fb5a56-ed25-453b-fda3-44f2e85c344e"
      },
      "source": [
        "parameters_grad = {\n",
        "  'booster':['gbtree','gblinear','dart'],\n",
        "  'eta':[0.001,0.01,0.1,1],\n",
        "  'max_depth':[10, 20, 30, 40, 80, 90, 100, None],\n",
        "  'max_features':['auto', 'sqrt', 'log2'],\n",
        "  'random_state': [42],\n",
        "  'min_samples_split':[0.125,0.25,0.5,1,2,3,4,6,10]\n",
        "}\n",
        "\n",
        "grid_xgb = GridSearchCV(estimator =xgb.XGBClassifier(), \n",
        "                          param_grid = parameters_grad, scoring = 'f1', cv = 5)\n",
        "grid_xgb.fit(X_train,y_train)\n",
        "pd.DataFrame(grid_xgb.cv_results_)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_booster</th>\n",
              "      <th>param_eta</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_max_features</th>\n",
              "      <th>param_min_samples_split</th>\n",
              "      <th>param_random_state</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.090335</td>\n",
              "      <td>0.008670</td>\n",
              "      <td>0.003063</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>gbtree</td>\n",
              "      <td>0.001</td>\n",
              "      <td>10</td>\n",
              "      <td>auto</td>\n",
              "      <td>0.125</td>\n",
              "      <td>42</td>\n",
              "      <td>{'booster': 'gbtree', 'eta': 0.001, 'max_depth...</td>\n",
              "      <td>0.606742</td>\n",
              "      <td>0.65625</td>\n",
              "      <td>0.575342</td>\n",
              "      <td>0.523077</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.572282</td>\n",
              "      <td>0.05638</td>\n",
              "      <td>1297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.083783</td>\n",
              "      <td>0.001129</td>\n",
              "      <td>0.003041</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>gbtree</td>\n",
              "      <td>0.001</td>\n",
              "      <td>10</td>\n",
              "      <td>auto</td>\n",
              "      <td>0.25</td>\n",
              "      <td>42</td>\n",
              "      <td>{'booster': 'gbtree', 'eta': 0.001, 'max_depth...</td>\n",
              "      <td>0.606742</td>\n",
              "      <td>0.65625</td>\n",
              "      <td>0.575342</td>\n",
              "      <td>0.523077</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.572282</td>\n",
              "      <td>0.05638</td>\n",
              "      <td>1297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.084087</td>\n",
              "      <td>0.001472</td>\n",
              "      <td>0.003022</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>gbtree</td>\n",
              "      <td>0.001</td>\n",
              "      <td>10</td>\n",
              "      <td>auto</td>\n",
              "      <td>0.5</td>\n",
              "      <td>42</td>\n",
              "      <td>{'booster': 'gbtree', 'eta': 0.001, 'max_depth...</td>\n",
              "      <td>0.606742</td>\n",
              "      <td>0.65625</td>\n",
              "      <td>0.575342</td>\n",
              "      <td>0.523077</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.572282</td>\n",
              "      <td>0.05638</td>\n",
              "      <td>1297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.086125</td>\n",
              "      <td>0.003018</td>\n",
              "      <td>0.003065</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>gbtree</td>\n",
              "      <td>0.001</td>\n",
              "      <td>10</td>\n",
              "      <td>auto</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>{'booster': 'gbtree', 'eta': 0.001, 'max_depth...</td>\n",
              "      <td>0.606742</td>\n",
              "      <td>0.65625</td>\n",
              "      <td>0.575342</td>\n",
              "      <td>0.523077</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.572282</td>\n",
              "      <td>0.05638</td>\n",
              "      <td>1297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.083805</td>\n",
              "      <td>0.001047</td>\n",
              "      <td>0.003113</td>\n",
              "      <td>0.000140</td>\n",
              "      <td>gbtree</td>\n",
              "      <td>0.001</td>\n",
              "      <td>10</td>\n",
              "      <td>auto</td>\n",
              "      <td>2</td>\n",
              "      <td>42</td>\n",
              "      <td>{'booster': 'gbtree', 'eta': 0.001, 'max_depth...</td>\n",
              "      <td>0.606742</td>\n",
              "      <td>0.65625</td>\n",
              "      <td>0.575342</td>\n",
              "      <td>0.523077</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.572282</td>\n",
              "      <td>0.05638</td>\n",
              "      <td>1297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2587</th>\n",
              "      <td>0.002980</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>dart</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>log2</td>\n",
              "      <td>2</td>\n",
              "      <td>42</td>\n",
              "      <td>{'booster': 'dart', 'eta': 1, 'max_depth': Non...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2588</th>\n",
              "      <td>0.002879</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>dart</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>log2</td>\n",
              "      <td>3</td>\n",
              "      <td>42</td>\n",
              "      <td>{'booster': 'dart', 'eta': 1, 'max_depth': Non...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2589</th>\n",
              "      <td>0.002996</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>dart</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>log2</td>\n",
              "      <td>4</td>\n",
              "      <td>42</td>\n",
              "      <td>{'booster': 'dart', 'eta': 1, 'max_depth': Non...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2590</th>\n",
              "      <td>0.002984</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>dart</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>log2</td>\n",
              "      <td>6</td>\n",
              "      <td>42</td>\n",
              "      <td>{'booster': 'dart', 'eta': 1, 'max_depth': Non...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2591</th>\n",
              "      <td>0.002986</td>\n",
              "      <td>0.000153</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>dart</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>log2</td>\n",
              "      <td>10</td>\n",
              "      <td>42</td>\n",
              "      <td>{'booster': 'dart', 'eta': 1, 'max_depth': Non...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2592</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2592 rows Ã— 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0          0.090335      0.008670  ...         0.05638             1297\n",
              "1          0.083783      0.001129  ...         0.05638             1297\n",
              "2          0.084087      0.001472  ...         0.05638             1297\n",
              "3          0.086125      0.003018  ...         0.05638             1297\n",
              "4          0.083805      0.001047  ...         0.05638             1297\n",
              "...             ...           ...  ...             ...              ...\n",
              "2587       0.002980      0.000305  ...             NaN             2452\n",
              "2588       0.002879      0.000034  ...             NaN             2453\n",
              "2589       0.002996      0.000183  ...             NaN             2454\n",
              "2590       0.002984      0.000095  ...             NaN             2499\n",
              "2591       0.002986      0.000153  ...             NaN             2592\n",
              "\n",
              "[2592 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCkCG7Vde0wd"
      },
      "source": [
        "grid_xgb.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAfi1FHBe7so"
      },
      "source": [
        "grid_xgb.best_score_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIzDEN3R7R4R"
      },
      "source": [
        "### _Aplying the best params in model_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JknxMoElfGoo"
      },
      "source": [
        "model_xgb = xgb.XGBClassifier(\n",
        " booster = 'gbtree',\n",
        " eta = 0.001,\n",
        " max_depth = 20,\n",
        " max_features = 'auto',\n",
        " min_samples_split = 0.125,\n",
        " random_state = 42\n",
        ")\n",
        "\n",
        "model_xgb.fit(X_train,y_train)\n",
        "model_xgb_train = model_xgb.predict(X_train)\n",
        "model_xgb_test = model_xgb.predict(X_test)\n",
        "print(f'The f1_score of train is {np.round(f1_score(y_train,model_xgb_train)*100)}% and the f1_score of test is {np.round(f1_score(y_test,model_xgb_test)*100,2)}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhbmVBw8Eh53"
      },
      "source": [
        "results['algorithm'].append('XGBoost')\n",
        "results['train score'].append(np.round(f1_score(y_train,model_xgb_train)*100))\n",
        "results['test score'].append(np.round(f1_score(y_test,model_xgb_test)*100,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ_vnFz14YTR"
      },
      "source": [
        "## `LightGBM` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmQqoVvG4fY6"
      },
      "source": [
        "parameters_light = {\n",
        "  'booster':['gbtree','gblinear','dart'],\n",
        "  'eta':[0.001,0.01,0.1,1],\n",
        "  'max_depth':[10, 20, 30, 40, 80, 90, 100, None],\n",
        "  'max_features':['auto', 'sqrt', 'log2'],\n",
        "  'random_state': [42],\n",
        "  'min_samples_split':[0.125,0.25,0.5,1,2,3,4,6,10]\n",
        "}\n",
        "\n",
        "grid_light = GridSearchCV(estimator = LGBMClassifier(), \n",
        "                          param_grid = parameters_light, scoring = 'f1')\n",
        "grid_light.fit(X_train,y_train)\n",
        "pd.DataFrame(grid_light.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2XAKX9M7BQx"
      },
      "source": [
        "grid_light.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0-tVpEb7Fzh",
        "outputId": "c71a197a-7134-4107-a3b9-17e4d62c2a7a"
      },
      "source": [
        "grid_light.best_score_"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5557423139520326"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW5ZYyT97TkO"
      },
      "source": [
        "### _Aplying the best params in model_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBvz9V-W7Uj2"
      },
      "source": [
        "model_light = LGBMClassifier(\n",
        "  booster = 'gbtree',\n",
        "  eta = 0.001,\n",
        "  max_depth = 20,\n",
        "  max_features = 'auto',\n",
        "  min_samples_split = 0.125,\n",
        "  random_state = 42\n",
        ")\n",
        "\n",
        "model_light.fit(X_train,y_train)\n",
        "model_light_train = model_light.predict(X_train)\n",
        "model_light_test = model_light.predict(X_test)\n",
        "print(f'The f1_score of train is {np.round(f1_score(y_train,model_light_train)*100)}% and the f1_score of test is {np.round(f1_score(y_test,model_light_test)*100,2)}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ2YDSGwEzm5"
      },
      "source": [
        "results['algorithm'].append('LGBM')\n",
        "results['train score'].append(np.round(f1_score(y_train,model_light_train)*100))\n",
        "results['test score'].append(np.round(f1_score(y_test,model_light_test)*100,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my6IX44SG1bT"
      },
      "source": [
        "## `Catboost`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSVWygUzG5Yf"
      },
      "source": [
        "parameters_cat = {\n",
        "  'learning_rate':[0.001,0.01,0.1,1],\n",
        "  'max_depth':[10, 20, 30, 40, 80, 90, 100],\n",
        "  'random_seed': [42]\n",
        "}\n",
        "\n",
        "grid_cat = GridSearchCV(estimator = CatBoostClassifier(), \n",
        "                          param_grid = parameters_cat, scoring = 'f1')\n",
        "grid_cat.fit(X_train,y_train)\n",
        "pd.DataFrame(grid_cat.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBJqhK-CJH1q"
      },
      "source": [
        "grid_cat.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SlnLKTGJMjQ"
      },
      "source": [
        "grid_cat.best_score_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JYqwMPfHmZy"
      },
      "source": [
        "### _Aplying the best params in model_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78oNG93dHoO_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5602e07c-2f4b-4e72-b341-c0cbc9aa098c"
      },
      "source": [
        "model_cat = CatBoostClassifier(\n",
        "  learning_rate = 0.01,\n",
        "  max_depth = 10,\n",
        "  random_seed = 42\n",
        ")\n",
        "\n",
        "model_cat.fit(X_train,y_train)\n",
        "model_cat_train = model_cat.predict(X_train)\n",
        "model_cat_test = model_cat.predict(X_test)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.6856822\ttotal: 15.5ms\tremaining: 15.5s\n",
            "1:\tlearn: 0.6800627\ttotal: 32.2ms\tremaining: 16.1s\n",
            "2:\tlearn: 0.6741949\ttotal: 45.6ms\tremaining: 15.2s\n",
            "3:\tlearn: 0.6678767\ttotal: 57.3ms\tremaining: 14.3s\n",
            "4:\tlearn: 0.6616683\ttotal: 69.6ms\tremaining: 13.9s\n",
            "5:\tlearn: 0.6563815\ttotal: 81.4ms\tremaining: 13.5s\n",
            "6:\tlearn: 0.6505787\ttotal: 93.2ms\tremaining: 13.2s\n",
            "7:\tlearn: 0.6450495\ttotal: 105ms\tremaining: 13s\n",
            "8:\tlearn: 0.6395385\ttotal: 117ms\tremaining: 12.8s\n",
            "9:\tlearn: 0.6344674\ttotal: 128ms\tremaining: 12.7s\n",
            "10:\tlearn: 0.6298752\ttotal: 140ms\tremaining: 12.6s\n",
            "11:\tlearn: 0.6244258\ttotal: 152ms\tremaining: 12.5s\n",
            "12:\tlearn: 0.6191443\ttotal: 163ms\tremaining: 12.4s\n",
            "13:\tlearn: 0.6140617\ttotal: 175ms\tremaining: 12.4s\n",
            "14:\tlearn: 0.6101496\ttotal: 178ms\tremaining: 11.7s\n",
            "15:\tlearn: 0.6053287\ttotal: 190ms\tremaining: 11.7s\n",
            "16:\tlearn: 0.6006162\ttotal: 203ms\tremaining: 11.7s\n",
            "17:\tlearn: 0.5962683\ttotal: 220ms\tremaining: 12s\n",
            "18:\tlearn: 0.5914335\ttotal: 232ms\tremaining: 12s\n",
            "19:\tlearn: 0.5866003\ttotal: 244ms\tremaining: 11.9s\n",
            "20:\tlearn: 0.5821325\ttotal: 255ms\tremaining: 11.9s\n",
            "21:\tlearn: 0.5775501\ttotal: 267ms\tremaining: 11.9s\n",
            "22:\tlearn: 0.5735255\ttotal: 279ms\tremaining: 11.9s\n",
            "23:\tlearn: 0.5695958\ttotal: 295ms\tremaining: 12s\n",
            "24:\tlearn: 0.5651081\ttotal: 306ms\tremaining: 11.9s\n",
            "25:\tlearn: 0.5609773\ttotal: 318ms\tremaining: 11.9s\n",
            "26:\tlearn: 0.5567164\ttotal: 329ms\tremaining: 11.9s\n",
            "27:\tlearn: 0.5533303\ttotal: 335ms\tremaining: 11.6s\n",
            "28:\tlearn: 0.5491727\ttotal: 346ms\tremaining: 11.6s\n",
            "29:\tlearn: 0.5453562\ttotal: 358ms\tremaining: 11.6s\n",
            "30:\tlearn: 0.5418631\ttotal: 370ms\tremaining: 11.6s\n",
            "31:\tlearn: 0.5379711\ttotal: 382ms\tremaining: 11.5s\n",
            "32:\tlearn: 0.5342925\ttotal: 393ms\tremaining: 11.5s\n",
            "33:\tlearn: 0.5308742\ttotal: 405ms\tremaining: 11.5s\n",
            "34:\tlearn: 0.5267949\ttotal: 422ms\tremaining: 11.6s\n",
            "35:\tlearn: 0.5231263\ttotal: 434ms\tremaining: 11.6s\n",
            "36:\tlearn: 0.5197103\ttotal: 446ms\tremaining: 11.6s\n",
            "37:\tlearn: 0.5165585\ttotal: 458ms\tremaining: 11.6s\n",
            "38:\tlearn: 0.5135105\ttotal: 470ms\tremaining: 11.6s\n",
            "39:\tlearn: 0.5104580\ttotal: 482ms\tremaining: 11.6s\n",
            "40:\tlearn: 0.5078052\ttotal: 494ms\tremaining: 11.5s\n",
            "41:\tlearn: 0.5045694\ttotal: 505ms\tremaining: 11.5s\n",
            "42:\tlearn: 0.5013560\ttotal: 517ms\tremaining: 11.5s\n",
            "43:\tlearn: 0.4984670\ttotal: 529ms\tremaining: 11.5s\n",
            "44:\tlearn: 0.4957652\ttotal: 541ms\tremaining: 11.5s\n",
            "45:\tlearn: 0.4922719\ttotal: 552ms\tremaining: 11.4s\n",
            "46:\tlearn: 0.4892622\ttotal: 565ms\tremaining: 11.5s\n",
            "47:\tlearn: 0.4857438\ttotal: 576ms\tremaining: 11.4s\n",
            "48:\tlearn: 0.4827938\ttotal: 588ms\tremaining: 11.4s\n",
            "49:\tlearn: 0.4798496\ttotal: 602ms\tremaining: 11.4s\n",
            "50:\tlearn: 0.4777498\ttotal: 617ms\tremaining: 11.5s\n",
            "51:\tlearn: 0.4748691\ttotal: 635ms\tremaining: 11.6s\n",
            "52:\tlearn: 0.4723748\ttotal: 646ms\tremaining: 11.5s\n",
            "53:\tlearn: 0.4700559\ttotal: 657ms\tremaining: 11.5s\n",
            "54:\tlearn: 0.4670843\ttotal: 669ms\tremaining: 11.5s\n",
            "55:\tlearn: 0.4643267\ttotal: 680ms\tremaining: 11.5s\n",
            "56:\tlearn: 0.4618927\ttotal: 691ms\tremaining: 11.4s\n",
            "57:\tlearn: 0.4590815\ttotal: 702ms\tremaining: 11.4s\n",
            "58:\tlearn: 0.4564935\ttotal: 714ms\tremaining: 11.4s\n",
            "59:\tlearn: 0.4542971\ttotal: 725ms\tremaining: 11.4s\n",
            "60:\tlearn: 0.4517272\ttotal: 736ms\tremaining: 11.3s\n",
            "61:\tlearn: 0.4500027\ttotal: 747ms\tremaining: 11.3s\n",
            "62:\tlearn: 0.4475105\ttotal: 759ms\tremaining: 11.3s\n",
            "63:\tlearn: 0.4456901\ttotal: 770ms\tremaining: 11.3s\n",
            "64:\tlearn: 0.4433305\ttotal: 782ms\tremaining: 11.2s\n",
            "65:\tlearn: 0.4408705\ttotal: 794ms\tremaining: 11.2s\n",
            "66:\tlearn: 0.4385314\ttotal: 805ms\tremaining: 11.2s\n",
            "67:\tlearn: 0.4364895\ttotal: 821ms\tremaining: 11.3s\n",
            "68:\tlearn: 0.4346581\ttotal: 833ms\tremaining: 11.2s\n",
            "69:\tlearn: 0.4324692\ttotal: 845ms\tremaining: 11.2s\n",
            "70:\tlearn: 0.4305184\ttotal: 856ms\tremaining: 11.2s\n",
            "71:\tlearn: 0.4286873\ttotal: 868ms\tremaining: 11.2s\n",
            "72:\tlearn: 0.4262885\ttotal: 879ms\tremaining: 11.2s\n",
            "73:\tlearn: 0.4242747\ttotal: 892ms\tremaining: 11.2s\n",
            "74:\tlearn: 0.4219163\ttotal: 907ms\tremaining: 11.2s\n",
            "75:\tlearn: 0.4196368\ttotal: 918ms\tremaining: 11.2s\n",
            "76:\tlearn: 0.4181086\ttotal: 930ms\tremaining: 11.1s\n",
            "77:\tlearn: 0.4156572\ttotal: 942ms\tremaining: 11.1s\n",
            "78:\tlearn: 0.4136372\ttotal: 954ms\tremaining: 11.1s\n",
            "79:\tlearn: 0.4116108\ttotal: 966ms\tremaining: 11.1s\n",
            "80:\tlearn: 0.4100952\ttotal: 978ms\tremaining: 11.1s\n",
            "81:\tlearn: 0.4081876\ttotal: 990ms\tremaining: 11.1s\n",
            "82:\tlearn: 0.4063060\ttotal: 1s\tremaining: 11.1s\n",
            "83:\tlearn: 0.4044413\ttotal: 1.01s\tremaining: 11s\n",
            "84:\tlearn: 0.4018483\ttotal: 1.03s\tremaining: 11.1s\n",
            "85:\tlearn: 0.4002279\ttotal: 1.04s\tremaining: 11.1s\n",
            "86:\tlearn: 0.3981701\ttotal: 1.05s\tremaining: 11.1s\n",
            "87:\tlearn: 0.3965286\ttotal: 1.06s\tremaining: 11s\n",
            "88:\tlearn: 0.3947921\ttotal: 1.08s\tremaining: 11s\n",
            "89:\tlearn: 0.3926463\ttotal: 1.09s\tremaining: 11s\n",
            "90:\tlearn: 0.3905073\ttotal: 1.1s\tremaining: 11s\n",
            "91:\tlearn: 0.3889651\ttotal: 1.11s\tremaining: 11s\n",
            "92:\tlearn: 0.3874205\ttotal: 1.12s\tremaining: 11s\n",
            "93:\tlearn: 0.3850344\ttotal: 1.13s\tremaining: 10.9s\n",
            "94:\tlearn: 0.3834002\ttotal: 1.15s\tremaining: 10.9s\n",
            "95:\tlearn: 0.3819014\ttotal: 1.16s\tremaining: 10.9s\n",
            "96:\tlearn: 0.3805425\ttotal: 1.17s\tremaining: 10.9s\n",
            "97:\tlearn: 0.3789623\ttotal: 1.18s\tremaining: 10.9s\n",
            "98:\tlearn: 0.3773654\ttotal: 1.19s\tremaining: 10.8s\n",
            "99:\tlearn: 0.3752090\ttotal: 1.2s\tremaining: 10.8s\n",
            "100:\tlearn: 0.3740771\ttotal: 1.21s\tremaining: 10.8s\n",
            "101:\tlearn: 0.3723206\ttotal: 1.23s\tremaining: 10.8s\n",
            "102:\tlearn: 0.3707182\ttotal: 1.24s\tremaining: 10.8s\n",
            "103:\tlearn: 0.3695689\ttotal: 1.25s\tremaining: 10.8s\n",
            "104:\tlearn: 0.3678819\ttotal: 1.26s\tremaining: 10.8s\n",
            "105:\tlearn: 0.3665812\ttotal: 1.28s\tremaining: 10.8s\n",
            "106:\tlearn: 0.3648987\ttotal: 1.29s\tremaining: 10.8s\n",
            "107:\tlearn: 0.3633780\ttotal: 1.3s\tremaining: 10.8s\n",
            "108:\tlearn: 0.3618762\ttotal: 1.31s\tremaining: 10.7s\n",
            "109:\tlearn: 0.3603836\ttotal: 1.32s\tremaining: 10.7s\n",
            "110:\tlearn: 0.3592172\ttotal: 1.34s\tremaining: 10.7s\n",
            "111:\tlearn: 0.3582169\ttotal: 1.34s\tremaining: 10.6s\n",
            "112:\tlearn: 0.3563968\ttotal: 1.35s\tremaining: 10.6s\n",
            "113:\tlearn: 0.3550182\ttotal: 1.36s\tremaining: 10.6s\n",
            "114:\tlearn: 0.3531684\ttotal: 1.37s\tremaining: 10.6s\n",
            "115:\tlearn: 0.3515720\ttotal: 1.39s\tremaining: 10.6s\n",
            "116:\tlearn: 0.3500279\ttotal: 1.4s\tremaining: 10.5s\n",
            "117:\tlearn: 0.3491379\ttotal: 1.41s\tremaining: 10.5s\n",
            "118:\tlearn: 0.3478261\ttotal: 1.42s\tremaining: 10.5s\n",
            "119:\tlearn: 0.3462085\ttotal: 1.43s\tremaining: 10.5s\n",
            "120:\tlearn: 0.3450479\ttotal: 1.45s\tremaining: 10.5s\n",
            "121:\tlearn: 0.3438389\ttotal: 1.46s\tremaining: 10.5s\n",
            "122:\tlearn: 0.3428002\ttotal: 1.47s\tremaining: 10.5s\n",
            "123:\tlearn: 0.3408281\ttotal: 1.48s\tremaining: 10.5s\n",
            "124:\tlearn: 0.3395474\ttotal: 1.49s\tremaining: 10.5s\n",
            "125:\tlearn: 0.3383135\ttotal: 1.5s\tremaining: 10.4s\n",
            "126:\tlearn: 0.3369215\ttotal: 1.51s\tremaining: 10.4s\n",
            "127:\tlearn: 0.3357098\ttotal: 1.53s\tremaining: 10.4s\n",
            "128:\tlearn: 0.3354167\ttotal: 1.53s\tremaining: 10.3s\n",
            "129:\tlearn: 0.3337571\ttotal: 1.54s\tremaining: 10.3s\n",
            "130:\tlearn: 0.3327395\ttotal: 1.55s\tremaining: 10.3s\n",
            "131:\tlearn: 0.3310299\ttotal: 1.56s\tremaining: 10.3s\n",
            "132:\tlearn: 0.3298891\ttotal: 1.57s\tremaining: 10.3s\n",
            "133:\tlearn: 0.3287513\ttotal: 1.58s\tremaining: 10.2s\n",
            "134:\tlearn: 0.3277733\ttotal: 1.6s\tremaining: 10.3s\n",
            "135:\tlearn: 0.3265339\ttotal: 1.62s\tremaining: 10.3s\n",
            "136:\tlearn: 0.3252221\ttotal: 1.63s\tremaining: 10.3s\n",
            "137:\tlearn: 0.3240376\ttotal: 1.64s\tremaining: 10.3s\n",
            "138:\tlearn: 0.3230075\ttotal: 1.66s\tremaining: 10.3s\n",
            "139:\tlearn: 0.3217227\ttotal: 1.67s\tremaining: 10.3s\n",
            "140:\tlearn: 0.3203275\ttotal: 1.68s\tremaining: 10.2s\n",
            "141:\tlearn: 0.3192521\ttotal: 1.69s\tremaining: 10.2s\n",
            "142:\tlearn: 0.3182383\ttotal: 1.71s\tremaining: 10.2s\n",
            "143:\tlearn: 0.3169978\ttotal: 1.72s\tremaining: 10.2s\n",
            "144:\tlearn: 0.3157878\ttotal: 1.73s\tremaining: 10.2s\n",
            "145:\tlearn: 0.3149770\ttotal: 1.74s\tremaining: 10.2s\n",
            "146:\tlearn: 0.3145211\ttotal: 1.74s\tremaining: 10.1s\n",
            "147:\tlearn: 0.3131799\ttotal: 1.75s\tremaining: 10.1s\n",
            "148:\tlearn: 0.3117331\ttotal: 1.76s\tremaining: 10.1s\n",
            "149:\tlearn: 0.3108420\ttotal: 1.78s\tremaining: 10.1s\n",
            "150:\tlearn: 0.3096065\ttotal: 1.79s\tremaining: 10.1s\n",
            "151:\tlearn: 0.3083043\ttotal: 1.8s\tremaining: 10s\n",
            "152:\tlearn: 0.3075229\ttotal: 1.81s\tremaining: 10s\n",
            "153:\tlearn: 0.3067765\ttotal: 1.82s\tremaining: 10s\n",
            "154:\tlearn: 0.3058345\ttotal: 1.83s\tremaining: 9.99s\n",
            "155:\tlearn: 0.3043268\ttotal: 1.84s\tremaining: 9.98s\n",
            "156:\tlearn: 0.3032868\ttotal: 1.86s\tremaining: 9.97s\n",
            "157:\tlearn: 0.3022163\ttotal: 1.87s\tremaining: 9.97s\n",
            "158:\tlearn: 0.3010634\ttotal: 1.88s\tremaining: 9.96s\n",
            "159:\tlearn: 0.2998731\ttotal: 1.9s\tremaining: 9.95s\n",
            "160:\tlearn: 0.2988053\ttotal: 1.91s\tremaining: 9.94s\n",
            "161:\tlearn: 0.2980181\ttotal: 1.92s\tremaining: 9.93s\n",
            "162:\tlearn: 0.2971289\ttotal: 1.93s\tremaining: 9.92s\n",
            "163:\tlearn: 0.2962296\ttotal: 1.94s\tremaining: 9.9s\n",
            "164:\tlearn: 0.2950824\ttotal: 1.95s\tremaining: 9.89s\n",
            "165:\tlearn: 0.2940862\ttotal: 1.97s\tremaining: 9.88s\n",
            "166:\tlearn: 0.2933708\ttotal: 1.98s\tremaining: 9.87s\n",
            "167:\tlearn: 0.2921713\ttotal: 1.99s\tremaining: 9.85s\n",
            "168:\tlearn: 0.2913454\ttotal: 2s\tremaining: 9.84s\n",
            "169:\tlearn: 0.2904695\ttotal: 2.01s\tremaining: 9.83s\n",
            "170:\tlearn: 0.2898176\ttotal: 2.02s\tremaining: 9.81s\n",
            "171:\tlearn: 0.2887497\ttotal: 2.04s\tremaining: 9.8s\n",
            "172:\tlearn: 0.2876482\ttotal: 2.05s\tremaining: 9.79s\n",
            "173:\tlearn: 0.2865981\ttotal: 2.06s\tremaining: 9.8s\n",
            "174:\tlearn: 0.2854833\ttotal: 2.08s\tremaining: 9.78s\n",
            "175:\tlearn: 0.2842227\ttotal: 2.09s\tremaining: 9.77s\n",
            "176:\tlearn: 0.2835053\ttotal: 2.1s\tremaining: 9.76s\n",
            "177:\tlearn: 0.2825399\ttotal: 2.11s\tremaining: 9.74s\n",
            "178:\tlearn: 0.2813952\ttotal: 2.12s\tremaining: 9.73s\n",
            "179:\tlearn: 0.2800485\ttotal: 2.13s\tremaining: 9.71s\n",
            "180:\tlearn: 0.2790508\ttotal: 2.14s\tremaining: 9.7s\n",
            "181:\tlearn: 0.2780255\ttotal: 2.15s\tremaining: 9.69s\n",
            "182:\tlearn: 0.2769058\ttotal: 2.17s\tremaining: 9.67s\n",
            "183:\tlearn: 0.2758331\ttotal: 2.18s\tremaining: 9.66s\n",
            "184:\tlearn: 0.2751235\ttotal: 2.19s\tremaining: 9.65s\n",
            "185:\tlearn: 0.2743212\ttotal: 2.2s\tremaining: 9.63s\n",
            "186:\tlearn: 0.2734887\ttotal: 2.21s\tremaining: 9.62s\n",
            "187:\tlearn: 0.2730218\ttotal: 2.22s\tremaining: 9.61s\n",
            "188:\tlearn: 0.2720728\ttotal: 2.24s\tremaining: 9.6s\n",
            "189:\tlearn: 0.2711483\ttotal: 2.25s\tremaining: 9.58s\n",
            "190:\tlearn: 0.2701931\ttotal: 2.26s\tremaining: 9.57s\n",
            "191:\tlearn: 0.2692312\ttotal: 2.27s\tremaining: 9.57s\n",
            "192:\tlearn: 0.2685025\ttotal: 2.29s\tremaining: 9.57s\n",
            "193:\tlearn: 0.2672830\ttotal: 2.3s\tremaining: 9.56s\n",
            "194:\tlearn: 0.2671096\ttotal: 2.3s\tremaining: 9.51s\n",
            "195:\tlearn: 0.2659617\ttotal: 2.31s\tremaining: 9.5s\n",
            "196:\tlearn: 0.2651110\ttotal: 2.33s\tremaining: 9.48s\n",
            "197:\tlearn: 0.2641501\ttotal: 2.34s\tremaining: 9.47s\n",
            "198:\tlearn: 0.2633929\ttotal: 2.35s\tremaining: 9.46s\n",
            "199:\tlearn: 0.2627628\ttotal: 2.36s\tremaining: 9.45s\n",
            "200:\tlearn: 0.2618392\ttotal: 2.37s\tremaining: 9.44s\n",
            "201:\tlearn: 0.2608912\ttotal: 2.38s\tremaining: 9.42s\n",
            "202:\tlearn: 0.2602394\ttotal: 2.4s\tremaining: 9.41s\n",
            "203:\tlearn: 0.2596622\ttotal: 2.41s\tremaining: 9.4s\n",
            "204:\tlearn: 0.2586943\ttotal: 2.42s\tremaining: 9.39s\n",
            "205:\tlearn: 0.2579561\ttotal: 2.43s\tremaining: 9.37s\n",
            "206:\tlearn: 0.2572322\ttotal: 2.44s\tremaining: 9.36s\n",
            "207:\tlearn: 0.2559075\ttotal: 2.46s\tremaining: 9.35s\n",
            "208:\tlearn: 0.2552667\ttotal: 2.47s\tremaining: 9.35s\n",
            "209:\tlearn: 0.2541313\ttotal: 2.48s\tremaining: 9.34s\n",
            "210:\tlearn: 0.2536186\ttotal: 2.49s\tremaining: 9.33s\n",
            "211:\tlearn: 0.2527046\ttotal: 2.51s\tremaining: 9.32s\n",
            "212:\tlearn: 0.2518773\ttotal: 2.52s\tremaining: 9.3s\n",
            "213:\tlearn: 0.2513479\ttotal: 2.53s\tremaining: 9.29s\n",
            "214:\tlearn: 0.2506845\ttotal: 2.54s\tremaining: 9.28s\n",
            "215:\tlearn: 0.2497843\ttotal: 2.55s\tremaining: 9.27s\n",
            "216:\tlearn: 0.2489534\ttotal: 2.56s\tremaining: 9.25s\n",
            "217:\tlearn: 0.2479015\ttotal: 2.58s\tremaining: 9.24s\n",
            "218:\tlearn: 0.2471504\ttotal: 2.59s\tremaining: 9.24s\n",
            "219:\tlearn: 0.2465967\ttotal: 2.61s\tremaining: 9.24s\n",
            "220:\tlearn: 0.2460738\ttotal: 2.62s\tremaining: 9.23s\n",
            "221:\tlearn: 0.2453811\ttotal: 2.63s\tremaining: 9.21s\n",
            "222:\tlearn: 0.2446737\ttotal: 2.64s\tremaining: 9.2s\n",
            "223:\tlearn: 0.2438377\ttotal: 2.65s\tremaining: 9.19s\n",
            "224:\tlearn: 0.2430234\ttotal: 2.66s\tremaining: 9.18s\n",
            "225:\tlearn: 0.2425368\ttotal: 2.68s\tremaining: 9.19s\n",
            "226:\tlearn: 0.2414958\ttotal: 2.69s\tremaining: 9.17s\n",
            "227:\tlearn: 0.2409534\ttotal: 2.71s\tremaining: 9.16s\n",
            "228:\tlearn: 0.2402947\ttotal: 2.72s\tremaining: 9.15s\n",
            "229:\tlearn: 0.2394149\ttotal: 2.73s\tremaining: 9.13s\n",
            "230:\tlearn: 0.2388819\ttotal: 2.74s\tremaining: 9.12s\n",
            "231:\tlearn: 0.2382959\ttotal: 2.75s\tremaining: 9.11s\n",
            "232:\tlearn: 0.2373701\ttotal: 2.76s\tremaining: 9.1s\n",
            "233:\tlearn: 0.2367984\ttotal: 2.77s\tremaining: 9.08s\n",
            "234:\tlearn: 0.2361191\ttotal: 2.79s\tremaining: 9.07s\n",
            "235:\tlearn: 0.2356459\ttotal: 2.8s\tremaining: 9.07s\n",
            "236:\tlearn: 0.2350325\ttotal: 2.81s\tremaining: 9.06s\n",
            "237:\tlearn: 0.2342473\ttotal: 2.82s\tremaining: 9.04s\n",
            "238:\tlearn: 0.2337546\ttotal: 2.84s\tremaining: 9.03s\n",
            "239:\tlearn: 0.2333728\ttotal: 2.85s\tremaining: 9.02s\n",
            "240:\tlearn: 0.2329586\ttotal: 2.86s\tremaining: 9.01s\n",
            "241:\tlearn: 0.2324138\ttotal: 2.87s\tremaining: 8.99s\n",
            "242:\tlearn: 0.2316500\ttotal: 2.89s\tremaining: 9s\n",
            "243:\tlearn: 0.2308098\ttotal: 2.9s\tremaining: 8.98s\n",
            "244:\tlearn: 0.2302694\ttotal: 2.91s\tremaining: 8.97s\n",
            "245:\tlearn: 0.2294615\ttotal: 2.92s\tremaining: 8.96s\n",
            "246:\tlearn: 0.2289083\ttotal: 2.94s\tremaining: 8.95s\n",
            "247:\tlearn: 0.2284866\ttotal: 2.95s\tremaining: 8.94s\n",
            "248:\tlearn: 0.2277943\ttotal: 2.96s\tremaining: 8.92s\n",
            "249:\tlearn: 0.2270768\ttotal: 2.97s\tremaining: 8.91s\n",
            "250:\tlearn: 0.2263784\ttotal: 2.98s\tremaining: 8.9s\n",
            "251:\tlearn: 0.2256563\ttotal: 2.99s\tremaining: 8.88s\n",
            "252:\tlearn: 0.2252725\ttotal: 3s\tremaining: 8.85s\n",
            "253:\tlearn: 0.2244256\ttotal: 3.01s\tremaining: 8.83s\n",
            "254:\tlearn: 0.2235141\ttotal: 3.02s\tremaining: 8.82s\n",
            "255:\tlearn: 0.2230757\ttotal: 3.03s\tremaining: 8.81s\n",
            "256:\tlearn: 0.2223789\ttotal: 3.04s\tremaining: 8.8s\n",
            "257:\tlearn: 0.2217489\ttotal: 3.06s\tremaining: 8.79s\n",
            "258:\tlearn: 0.2210277\ttotal: 3.07s\tremaining: 8.78s\n",
            "259:\tlearn: 0.2203404\ttotal: 3.08s\tremaining: 8.76s\n",
            "260:\tlearn: 0.2198511\ttotal: 3.1s\tremaining: 8.77s\n",
            "261:\tlearn: 0.2189735\ttotal: 3.11s\tremaining: 8.75s\n",
            "262:\tlearn: 0.2181803\ttotal: 3.12s\tremaining: 8.74s\n",
            "263:\tlearn: 0.2175166\ttotal: 3.13s\tremaining: 8.73s\n",
            "264:\tlearn: 0.2169159\ttotal: 3.14s\tremaining: 8.72s\n",
            "265:\tlearn: 0.2163701\ttotal: 3.15s\tremaining: 8.7s\n",
            "266:\tlearn: 0.2160316\ttotal: 3.17s\tremaining: 8.69s\n",
            "267:\tlearn: 0.2153321\ttotal: 3.18s\tremaining: 8.68s\n",
            "268:\tlearn: 0.2148788\ttotal: 3.19s\tremaining: 8.66s\n",
            "269:\tlearn: 0.2141670\ttotal: 3.2s\tremaining: 8.65s\n",
            "270:\tlearn: 0.2134272\ttotal: 3.21s\tremaining: 8.64s\n",
            "271:\tlearn: 0.2126830\ttotal: 3.22s\tremaining: 8.63s\n",
            "272:\tlearn: 0.2121225\ttotal: 3.23s\tremaining: 8.61s\n",
            "273:\tlearn: 0.2115378\ttotal: 3.25s\tremaining: 8.6s\n",
            "274:\tlearn: 0.2108691\ttotal: 3.26s\tremaining: 8.59s\n",
            "275:\tlearn: 0.2105057\ttotal: 3.27s\tremaining: 8.57s\n",
            "276:\tlearn: 0.2100067\ttotal: 3.28s\tremaining: 8.56s\n",
            "277:\tlearn: 0.2094319\ttotal: 3.29s\tremaining: 8.55s\n",
            "278:\tlearn: 0.2090243\ttotal: 3.31s\tremaining: 8.56s\n",
            "279:\tlearn: 0.2087719\ttotal: 3.33s\tremaining: 8.58s\n",
            "280:\tlearn: 0.2082005\ttotal: 3.35s\tremaining: 8.56s\n",
            "281:\tlearn: 0.2076492\ttotal: 3.36s\tremaining: 8.55s\n",
            "282:\tlearn: 0.2072538\ttotal: 3.37s\tremaining: 8.54s\n",
            "283:\tlearn: 0.2069633\ttotal: 3.38s\tremaining: 8.53s\n",
            "284:\tlearn: 0.2066428\ttotal: 3.39s\tremaining: 8.52s\n",
            "285:\tlearn: 0.2058673\ttotal: 3.41s\tremaining: 8.5s\n",
            "286:\tlearn: 0.2052948\ttotal: 3.42s\tremaining: 8.49s\n",
            "287:\tlearn: 0.2050088\ttotal: 3.43s\tremaining: 8.48s\n",
            "288:\tlearn: 0.2044958\ttotal: 3.44s\tremaining: 8.46s\n",
            "289:\tlearn: 0.2038224\ttotal: 3.45s\tremaining: 8.45s\n",
            "290:\tlearn: 0.2035361\ttotal: 3.46s\tremaining: 8.44s\n",
            "291:\tlearn: 0.2032050\ttotal: 3.47s\tremaining: 8.42s\n",
            "292:\tlearn: 0.2025201\ttotal: 3.49s\tremaining: 8.41s\n",
            "293:\tlearn: 0.2019069\ttotal: 3.5s\tremaining: 8.4s\n",
            "294:\tlearn: 0.2011850\ttotal: 3.51s\tremaining: 8.39s\n",
            "295:\tlearn: 0.2007988\ttotal: 3.52s\tremaining: 8.38s\n",
            "296:\tlearn: 0.2003614\ttotal: 3.54s\tremaining: 8.37s\n",
            "297:\tlearn: 0.1998456\ttotal: 3.55s\tremaining: 8.36s\n",
            "298:\tlearn: 0.1995144\ttotal: 3.56s\tremaining: 8.34s\n",
            "299:\tlearn: 0.1989480\ttotal: 3.57s\tremaining: 8.33s\n",
            "300:\tlearn: 0.1983872\ttotal: 3.59s\tremaining: 8.34s\n",
            "301:\tlearn: 0.1977745\ttotal: 3.61s\tremaining: 8.34s\n",
            "302:\tlearn: 0.1970472\ttotal: 3.62s\tremaining: 8.32s\n",
            "303:\tlearn: 0.1966475\ttotal: 3.63s\tremaining: 8.31s\n",
            "304:\tlearn: 0.1962741\ttotal: 3.64s\tremaining: 8.3s\n",
            "305:\tlearn: 0.1958381\ttotal: 3.65s\tremaining: 8.29s\n",
            "306:\tlearn: 0.1952528\ttotal: 3.67s\tremaining: 8.27s\n",
            "307:\tlearn: 0.1946695\ttotal: 3.68s\tremaining: 8.26s\n",
            "308:\tlearn: 0.1942170\ttotal: 3.69s\tremaining: 8.25s\n",
            "309:\tlearn: 0.1936491\ttotal: 3.7s\tremaining: 8.23s\n",
            "310:\tlearn: 0.1931874\ttotal: 3.72s\tremaining: 8.23s\n",
            "311:\tlearn: 0.1925931\ttotal: 3.73s\tremaining: 8.22s\n",
            "312:\tlearn: 0.1921212\ttotal: 3.74s\tremaining: 8.21s\n",
            "313:\tlearn: 0.1915624\ttotal: 3.75s\tremaining: 8.2s\n",
            "314:\tlearn: 0.1911554\ttotal: 3.76s\tremaining: 8.18s\n",
            "315:\tlearn: 0.1908193\ttotal: 3.77s\tremaining: 8.17s\n",
            "316:\tlearn: 0.1904670\ttotal: 3.79s\tremaining: 8.15s\n",
            "317:\tlearn: 0.1898106\ttotal: 3.8s\tremaining: 8.14s\n",
            "318:\tlearn: 0.1893073\ttotal: 3.81s\tremaining: 8.13s\n",
            "319:\tlearn: 0.1889208\ttotal: 3.82s\tremaining: 8.12s\n",
            "320:\tlearn: 0.1883165\ttotal: 3.83s\tremaining: 8.1s\n",
            "321:\tlearn: 0.1878729\ttotal: 3.84s\tremaining: 8.09s\n",
            "322:\tlearn: 0.1874066\ttotal: 3.85s\tremaining: 8.08s\n",
            "323:\tlearn: 0.1871955\ttotal: 3.87s\tremaining: 8.07s\n",
            "324:\tlearn: 0.1866318\ttotal: 3.88s\tremaining: 8.05s\n",
            "325:\tlearn: 0.1863446\ttotal: 3.89s\tremaining: 8.04s\n",
            "326:\tlearn: 0.1857314\ttotal: 3.9s\tremaining: 8.03s\n",
            "327:\tlearn: 0.1854423\ttotal: 3.92s\tremaining: 8.03s\n",
            "328:\tlearn: 0.1848621\ttotal: 3.93s\tremaining: 8.02s\n",
            "329:\tlearn: 0.1842171\ttotal: 3.94s\tremaining: 8.01s\n",
            "330:\tlearn: 0.1837162\ttotal: 3.96s\tremaining: 7.99s\n",
            "331:\tlearn: 0.1834469\ttotal: 3.97s\tremaining: 7.98s\n",
            "332:\tlearn: 0.1831382\ttotal: 3.98s\tremaining: 7.97s\n",
            "333:\tlearn: 0.1826795\ttotal: 3.99s\tremaining: 7.96s\n",
            "334:\tlearn: 0.1823703\ttotal: 4s\tremaining: 7.94s\n",
            "335:\tlearn: 0.1819062\ttotal: 4.01s\tremaining: 7.93s\n",
            "336:\tlearn: 0.1813704\ttotal: 4.02s\tremaining: 7.92s\n",
            "337:\tlearn: 0.1809693\ttotal: 4.04s\tremaining: 7.91s\n",
            "338:\tlearn: 0.1806663\ttotal: 4.05s\tremaining: 7.89s\n",
            "339:\tlearn: 0.1801854\ttotal: 4.06s\tremaining: 7.88s\n",
            "340:\tlearn: 0.1798341\ttotal: 4.07s\tremaining: 7.87s\n",
            "341:\tlearn: 0.1794876\ttotal: 4.08s\tremaining: 7.86s\n",
            "342:\tlearn: 0.1790852\ttotal: 4.09s\tremaining: 7.84s\n",
            "343:\tlearn: 0.1786465\ttotal: 4.11s\tremaining: 7.83s\n",
            "344:\tlearn: 0.1783548\ttotal: 4.12s\tremaining: 7.82s\n",
            "345:\tlearn: 0.1779105\ttotal: 4.13s\tremaining: 7.82s\n",
            "346:\tlearn: 0.1774853\ttotal: 4.15s\tremaining: 7.8s\n",
            "347:\tlearn: 0.1770999\ttotal: 4.16s\tremaining: 7.79s\n",
            "348:\tlearn: 0.1766907\ttotal: 4.17s\tremaining: 7.78s\n",
            "349:\tlearn: 0.1764058\ttotal: 4.18s\tremaining: 7.76s\n",
            "350:\tlearn: 0.1760344\ttotal: 4.19s\tremaining: 7.75s\n",
            "351:\tlearn: 0.1757335\ttotal: 4.2s\tremaining: 7.74s\n",
            "352:\tlearn: 0.1753768\ttotal: 4.22s\tremaining: 7.73s\n",
            "353:\tlearn: 0.1747852\ttotal: 4.23s\tremaining: 7.71s\n",
            "354:\tlearn: 0.1745078\ttotal: 4.24s\tremaining: 7.7s\n",
            "355:\tlearn: 0.1739871\ttotal: 4.25s\tremaining: 7.69s\n",
            "356:\tlearn: 0.1735075\ttotal: 4.26s\tremaining: 7.68s\n",
            "357:\tlearn: 0.1730911\ttotal: 4.27s\tremaining: 7.66s\n",
            "358:\tlearn: 0.1726499\ttotal: 4.29s\tremaining: 7.66s\n",
            "359:\tlearn: 0.1722613\ttotal: 4.3s\tremaining: 7.64s\n",
            "360:\tlearn: 0.1720258\ttotal: 4.31s\tremaining: 7.63s\n",
            "361:\tlearn: 0.1717718\ttotal: 4.33s\tremaining: 7.63s\n",
            "362:\tlearn: 0.1715293\ttotal: 4.34s\tremaining: 7.62s\n",
            "363:\tlearn: 0.1710800\ttotal: 4.35s\tremaining: 7.61s\n",
            "364:\tlearn: 0.1706401\ttotal: 4.37s\tremaining: 7.59s\n",
            "365:\tlearn: 0.1700885\ttotal: 4.38s\tremaining: 7.58s\n",
            "366:\tlearn: 0.1695652\ttotal: 4.39s\tremaining: 7.57s\n",
            "367:\tlearn: 0.1691585\ttotal: 4.4s\tremaining: 7.56s\n",
            "368:\tlearn: 0.1687223\ttotal: 4.41s\tremaining: 7.54s\n",
            "369:\tlearn: 0.1682854\ttotal: 4.42s\tremaining: 7.53s\n",
            "370:\tlearn: 0.1680083\ttotal: 4.43s\tremaining: 7.52s\n",
            "371:\tlearn: 0.1677902\ttotal: 4.45s\tremaining: 7.51s\n",
            "372:\tlearn: 0.1675234\ttotal: 4.46s\tremaining: 7.49s\n",
            "373:\tlearn: 0.1670418\ttotal: 4.47s\tremaining: 7.48s\n",
            "374:\tlearn: 0.1665688\ttotal: 4.48s\tremaining: 7.47s\n",
            "375:\tlearn: 0.1662878\ttotal: 4.49s\tremaining: 7.46s\n",
            "376:\tlearn: 0.1658876\ttotal: 4.51s\tremaining: 7.45s\n",
            "377:\tlearn: 0.1655739\ttotal: 4.52s\tremaining: 7.43s\n",
            "378:\tlearn: 0.1652205\ttotal: 4.53s\tremaining: 7.43s\n",
            "379:\tlearn: 0.1646329\ttotal: 4.55s\tremaining: 7.42s\n",
            "380:\tlearn: 0.1643489\ttotal: 4.56s\tremaining: 7.41s\n",
            "381:\tlearn: 0.1640941\ttotal: 4.57s\tremaining: 7.39s\n",
            "382:\tlearn: 0.1636443\ttotal: 4.58s\tremaining: 7.38s\n",
            "383:\tlearn: 0.1632741\ttotal: 4.6s\tremaining: 7.39s\n",
            "384:\tlearn: 0.1629090\ttotal: 4.62s\tremaining: 7.37s\n",
            "385:\tlearn: 0.1626312\ttotal: 4.63s\tremaining: 7.36s\n",
            "386:\tlearn: 0.1623042\ttotal: 4.64s\tremaining: 7.35s\n",
            "387:\tlearn: 0.1621100\ttotal: 4.65s\tremaining: 7.34s\n",
            "388:\tlearn: 0.1617624\ttotal: 4.66s\tremaining: 7.33s\n",
            "389:\tlearn: 0.1615063\ttotal: 4.67s\tremaining: 7.31s\n",
            "390:\tlearn: 0.1610513\ttotal: 4.69s\tremaining: 7.3s\n",
            "391:\tlearn: 0.1607996\ttotal: 4.7s\tremaining: 7.29s\n",
            "392:\tlearn: 0.1605635\ttotal: 4.71s\tremaining: 7.27s\n",
            "393:\tlearn: 0.1601445\ttotal: 4.72s\tremaining: 7.26s\n",
            "394:\tlearn: 0.1598639\ttotal: 4.73s\tremaining: 7.25s\n",
            "395:\tlearn: 0.1594404\ttotal: 4.75s\tremaining: 7.24s\n",
            "396:\tlearn: 0.1590895\ttotal: 4.76s\tremaining: 7.23s\n",
            "397:\tlearn: 0.1586462\ttotal: 4.77s\tremaining: 7.22s\n",
            "398:\tlearn: 0.1583740\ttotal: 4.78s\tremaining: 7.21s\n",
            "399:\tlearn: 0.1578010\ttotal: 4.8s\tremaining: 7.19s\n",
            "400:\tlearn: 0.1575139\ttotal: 4.81s\tremaining: 7.18s\n",
            "401:\tlearn: 0.1573162\ttotal: 4.82s\tremaining: 7.17s\n",
            "402:\tlearn: 0.1571367\ttotal: 4.83s\tremaining: 7.16s\n",
            "403:\tlearn: 0.1568693\ttotal: 4.84s\tremaining: 7.14s\n",
            "404:\tlearn: 0.1566359\ttotal: 4.85s\tremaining: 7.13s\n",
            "405:\tlearn: 0.1563204\ttotal: 4.86s\tremaining: 7.12s\n",
            "406:\tlearn: 0.1560053\ttotal: 4.88s\tremaining: 7.1s\n",
            "407:\tlearn: 0.1555976\ttotal: 4.89s\tremaining: 7.1s\n",
            "408:\tlearn: 0.1553506\ttotal: 4.91s\tremaining: 7.09s\n",
            "409:\tlearn: 0.1550498\ttotal: 4.92s\tremaining: 7.08s\n",
            "410:\tlearn: 0.1547480\ttotal: 4.93s\tremaining: 7.06s\n",
            "411:\tlearn: 0.1542420\ttotal: 4.95s\tremaining: 7.06s\n",
            "412:\tlearn: 0.1538007\ttotal: 4.96s\tremaining: 7.05s\n",
            "413:\tlearn: 0.1535018\ttotal: 4.97s\tremaining: 7.04s\n",
            "414:\tlearn: 0.1531691\ttotal: 4.98s\tremaining: 7.02s\n",
            "415:\tlearn: 0.1528696\ttotal: 4.99s\tremaining: 7.01s\n",
            "416:\tlearn: 0.1524491\ttotal: 5s\tremaining: 7s\n",
            "417:\tlearn: 0.1521343\ttotal: 5.02s\tremaining: 6.98s\n",
            "418:\tlearn: 0.1518224\ttotal: 5.03s\tremaining: 6.97s\n",
            "419:\tlearn: 0.1514493\ttotal: 5.04s\tremaining: 6.96s\n",
            "420:\tlearn: 0.1509826\ttotal: 5.05s\tremaining: 6.95s\n",
            "421:\tlearn: 0.1506878\ttotal: 5.06s\tremaining: 6.93s\n",
            "422:\tlearn: 0.1504374\ttotal: 5.07s\tremaining: 6.92s\n",
            "423:\tlearn: 0.1499744\ttotal: 5.08s\tremaining: 6.91s\n",
            "424:\tlearn: 0.1497222\ttotal: 5.1s\tremaining: 6.89s\n",
            "425:\tlearn: 0.1494017\ttotal: 5.11s\tremaining: 6.88s\n",
            "426:\tlearn: 0.1489251\ttotal: 5.12s\tremaining: 6.88s\n",
            "427:\tlearn: 0.1485546\ttotal: 5.13s\tremaining: 6.86s\n",
            "428:\tlearn: 0.1483149\ttotal: 5.15s\tremaining: 6.86s\n",
            "429:\tlearn: 0.1480413\ttotal: 5.16s\tremaining: 6.84s\n",
            "430:\tlearn: 0.1475827\ttotal: 5.17s\tremaining: 6.83s\n",
            "431:\tlearn: 0.1472752\ttotal: 5.18s\tremaining: 6.82s\n",
            "432:\tlearn: 0.1469055\ttotal: 5.2s\tremaining: 6.8s\n",
            "433:\tlearn: 0.1466351\ttotal: 5.21s\tremaining: 6.79s\n",
            "434:\tlearn: 0.1462922\ttotal: 5.22s\tremaining: 6.78s\n",
            "435:\tlearn: 0.1459618\ttotal: 5.23s\tremaining: 6.77s\n",
            "436:\tlearn: 0.1456373\ttotal: 5.24s\tremaining: 6.75s\n",
            "437:\tlearn: 0.1453770\ttotal: 5.25s\tremaining: 6.74s\n",
            "438:\tlearn: 0.1450483\ttotal: 5.26s\tremaining: 6.73s\n",
            "439:\tlearn: 0.1447735\ttotal: 5.28s\tremaining: 6.71s\n",
            "440:\tlearn: 0.1445141\ttotal: 5.29s\tremaining: 6.71s\n",
            "441:\tlearn: 0.1442982\ttotal: 5.3s\tremaining: 6.69s\n",
            "442:\tlearn: 0.1439642\ttotal: 5.31s\tremaining: 6.68s\n",
            "443:\tlearn: 0.1438003\ttotal: 5.32s\tremaining: 6.67s\n",
            "444:\tlearn: 0.1435343\ttotal: 5.33s\tremaining: 6.65s\n",
            "445:\tlearn: 0.1433602\ttotal: 5.34s\tremaining: 6.63s\n",
            "446:\tlearn: 0.1431531\ttotal: 5.36s\tremaining: 6.63s\n",
            "447:\tlearn: 0.1428820\ttotal: 5.37s\tremaining: 6.62s\n",
            "448:\tlearn: 0.1426689\ttotal: 5.38s\tremaining: 6.6s\n",
            "449:\tlearn: 0.1423308\ttotal: 5.39s\tremaining: 6.59s\n",
            "450:\tlearn: 0.1420126\ttotal: 5.4s\tremaining: 6.58s\n",
            "451:\tlearn: 0.1416566\ttotal: 5.42s\tremaining: 6.57s\n",
            "452:\tlearn: 0.1412103\ttotal: 5.43s\tremaining: 6.55s\n",
            "453:\tlearn: 0.1409063\ttotal: 5.44s\tremaining: 6.54s\n",
            "454:\tlearn: 0.1404949\ttotal: 5.45s\tremaining: 6.53s\n",
            "455:\tlearn: 0.1402468\ttotal: 5.46s\tremaining: 6.52s\n",
            "456:\tlearn: 0.1397488\ttotal: 5.47s\tremaining: 6.5s\n",
            "457:\tlearn: 0.1394465\ttotal: 5.49s\tremaining: 6.49s\n",
            "458:\tlearn: 0.1392039\ttotal: 5.5s\tremaining: 6.48s\n",
            "459:\tlearn: 0.1388306\ttotal: 5.51s\tremaining: 6.47s\n",
            "460:\tlearn: 0.1385671\ttotal: 5.52s\tremaining: 6.45s\n",
            "461:\tlearn: 0.1382890\ttotal: 5.53s\tremaining: 6.44s\n",
            "462:\tlearn: 0.1380426\ttotal: 5.54s\tremaining: 6.43s\n",
            "463:\tlearn: 0.1377799\ttotal: 5.55s\tremaining: 6.42s\n",
            "464:\tlearn: 0.1375466\ttotal: 5.57s\tremaining: 6.41s\n",
            "465:\tlearn: 0.1371645\ttotal: 5.58s\tremaining: 6.4s\n",
            "466:\tlearn: 0.1368337\ttotal: 5.61s\tremaining: 6.4s\n",
            "467:\tlearn: 0.1366919\ttotal: 5.62s\tremaining: 6.38s\n",
            "468:\tlearn: 0.1363444\ttotal: 5.63s\tremaining: 6.37s\n",
            "469:\tlearn: 0.1361589\ttotal: 5.64s\tremaining: 6.36s\n",
            "470:\tlearn: 0.1357477\ttotal: 5.65s\tremaining: 6.35s\n",
            "471:\tlearn: 0.1353866\ttotal: 5.66s\tremaining: 6.33s\n",
            "472:\tlearn: 0.1350995\ttotal: 5.67s\tremaining: 6.32s\n",
            "473:\tlearn: 0.1346835\ttotal: 5.69s\tremaining: 6.31s\n",
            "474:\tlearn: 0.1344036\ttotal: 5.7s\tremaining: 6.3s\n",
            "475:\tlearn: 0.1341161\ttotal: 5.71s\tremaining: 6.29s\n",
            "476:\tlearn: 0.1338208\ttotal: 5.72s\tremaining: 6.27s\n",
            "477:\tlearn: 0.1336105\ttotal: 5.73s\tremaining: 6.26s\n",
            "478:\tlearn: 0.1334897\ttotal: 5.74s\tremaining: 6.25s\n",
            "479:\tlearn: 0.1331605\ttotal: 5.75s\tremaining: 6.23s\n",
            "480:\tlearn: 0.1327841\ttotal: 5.77s\tremaining: 6.22s\n",
            "481:\tlearn: 0.1323963\ttotal: 5.79s\tremaining: 6.22s\n",
            "482:\tlearn: 0.1320919\ttotal: 5.8s\tremaining: 6.21s\n",
            "483:\tlearn: 0.1317578\ttotal: 5.81s\tremaining: 6.19s\n",
            "484:\tlearn: 0.1316149\ttotal: 5.82s\tremaining: 6.18s\n",
            "485:\tlearn: 0.1314403\ttotal: 5.83s\tremaining: 6.17s\n",
            "486:\tlearn: 0.1310224\ttotal: 5.84s\tremaining: 6.16s\n",
            "487:\tlearn: 0.1308089\ttotal: 5.86s\tremaining: 6.14s\n",
            "488:\tlearn: 0.1305846\ttotal: 5.87s\tremaining: 6.13s\n",
            "489:\tlearn: 0.1302854\ttotal: 5.88s\tremaining: 6.12s\n",
            "490:\tlearn: 0.1298844\ttotal: 5.89s\tremaining: 6.11s\n",
            "491:\tlearn: 0.1296015\ttotal: 5.9s\tremaining: 6.09s\n",
            "492:\tlearn: 0.1293428\ttotal: 5.91s\tremaining: 6.08s\n",
            "493:\tlearn: 0.1290401\ttotal: 5.93s\tremaining: 6.07s\n",
            "494:\tlearn: 0.1287333\ttotal: 5.94s\tremaining: 6.06s\n",
            "495:\tlearn: 0.1284429\ttotal: 5.95s\tremaining: 6.05s\n",
            "496:\tlearn: 0.1281943\ttotal: 5.96s\tremaining: 6.03s\n",
            "497:\tlearn: 0.1279355\ttotal: 5.97s\tremaining: 6.02s\n",
            "498:\tlearn: 0.1276626\ttotal: 5.99s\tremaining: 6.01s\n",
            "499:\tlearn: 0.1275029\ttotal: 6s\tremaining: 6s\n",
            "500:\tlearn: 0.1271905\ttotal: 6.01s\tremaining: 5.99s\n",
            "501:\tlearn: 0.1270663\ttotal: 6.02s\tremaining: 5.97s\n",
            "502:\tlearn: 0.1268005\ttotal: 6.04s\tremaining: 5.96s\n",
            "503:\tlearn: 0.1265794\ttotal: 6.05s\tremaining: 5.95s\n",
            "504:\tlearn: 0.1262263\ttotal: 6.06s\tremaining: 5.94s\n",
            "505:\tlearn: 0.1259024\ttotal: 6.07s\tremaining: 5.92s\n",
            "506:\tlearn: 0.1256216\ttotal: 6.08s\tremaining: 5.91s\n",
            "507:\tlearn: 0.1253605\ttotal: 6.09s\tremaining: 5.9s\n",
            "508:\tlearn: 0.1251830\ttotal: 6.1s\tremaining: 5.89s\n",
            "509:\tlearn: 0.1248476\ttotal: 6.12s\tremaining: 5.88s\n",
            "510:\tlearn: 0.1244822\ttotal: 6.13s\tremaining: 5.86s\n",
            "511:\tlearn: 0.1241729\ttotal: 6.14s\tremaining: 5.85s\n",
            "512:\tlearn: 0.1238567\ttotal: 6.15s\tremaining: 5.84s\n",
            "513:\tlearn: 0.1235612\ttotal: 6.16s\tremaining: 5.83s\n",
            "514:\tlearn: 0.1232735\ttotal: 6.17s\tremaining: 5.81s\n",
            "515:\tlearn: 0.1230570\ttotal: 6.18s\tremaining: 5.8s\n",
            "516:\tlearn: 0.1228672\ttotal: 6.2s\tremaining: 5.79s\n",
            "517:\tlearn: 0.1226988\ttotal: 6.21s\tremaining: 5.78s\n",
            "518:\tlearn: 0.1224158\ttotal: 6.22s\tremaining: 5.77s\n",
            "519:\tlearn: 0.1221996\ttotal: 6.23s\tremaining: 5.75s\n",
            "520:\tlearn: 0.1219898\ttotal: 6.24s\tremaining: 5.74s\n",
            "521:\tlearn: 0.1217610\ttotal: 6.26s\tremaining: 5.73s\n",
            "522:\tlearn: 0.1215281\ttotal: 6.27s\tremaining: 5.72s\n",
            "523:\tlearn: 0.1214268\ttotal: 6.28s\tremaining: 5.7s\n",
            "524:\tlearn: 0.1212129\ttotal: 6.29s\tremaining: 5.69s\n",
            "525:\tlearn: 0.1209180\ttotal: 6.3s\tremaining: 5.68s\n",
            "526:\tlearn: 0.1206071\ttotal: 6.31s\tremaining: 5.67s\n",
            "527:\tlearn: 0.1204355\ttotal: 6.32s\tremaining: 5.65s\n",
            "528:\tlearn: 0.1201905\ttotal: 6.34s\tremaining: 5.64s\n",
            "529:\tlearn: 0.1199072\ttotal: 6.35s\tremaining: 5.63s\n",
            "530:\tlearn: 0.1198025\ttotal: 6.36s\tremaining: 5.62s\n",
            "531:\tlearn: 0.1196246\ttotal: 6.37s\tremaining: 5.6s\n",
            "532:\tlearn: 0.1194559\ttotal: 6.38s\tremaining: 5.59s\n",
            "533:\tlearn: 0.1192592\ttotal: 6.39s\tremaining: 5.58s\n",
            "534:\tlearn: 0.1189718\ttotal: 6.41s\tremaining: 5.57s\n",
            "535:\tlearn: 0.1187266\ttotal: 6.42s\tremaining: 5.56s\n",
            "536:\tlearn: 0.1185258\ttotal: 6.44s\tremaining: 5.55s\n",
            "537:\tlearn: 0.1181935\ttotal: 6.45s\tremaining: 5.54s\n",
            "538:\tlearn: 0.1179668\ttotal: 6.46s\tremaining: 5.52s\n",
            "539:\tlearn: 0.1177350\ttotal: 6.46s\tremaining: 5.51s\n",
            "540:\tlearn: 0.1175323\ttotal: 6.48s\tremaining: 5.5s\n",
            "541:\tlearn: 0.1172841\ttotal: 6.49s\tremaining: 5.48s\n",
            "542:\tlearn: 0.1171459\ttotal: 6.5s\tremaining: 5.47s\n",
            "543:\tlearn: 0.1169834\ttotal: 6.51s\tremaining: 5.46s\n",
            "544:\tlearn: 0.1166978\ttotal: 6.52s\tremaining: 5.45s\n",
            "545:\tlearn: 0.1164317\ttotal: 6.53s\tremaining: 5.43s\n",
            "546:\tlearn: 0.1163870\ttotal: 6.54s\tremaining: 5.41s\n",
            "547:\tlearn: 0.1163621\ttotal: 6.54s\tremaining: 5.39s\n",
            "548:\tlearn: 0.1161327\ttotal: 6.55s\tremaining: 5.38s\n",
            "549:\tlearn: 0.1159298\ttotal: 6.56s\tremaining: 5.37s\n",
            "550:\tlearn: 0.1157257\ttotal: 6.57s\tremaining: 5.36s\n",
            "551:\tlearn: 0.1156218\ttotal: 6.58s\tremaining: 5.34s\n",
            "552:\tlearn: 0.1154022\ttotal: 6.6s\tremaining: 5.34s\n",
            "553:\tlearn: 0.1151746\ttotal: 6.62s\tremaining: 5.33s\n",
            "554:\tlearn: 0.1150329\ttotal: 6.63s\tremaining: 5.32s\n",
            "555:\tlearn: 0.1149341\ttotal: 6.64s\tremaining: 5.3s\n",
            "556:\tlearn: 0.1147611\ttotal: 6.65s\tremaining: 5.29s\n",
            "557:\tlearn: 0.1144846\ttotal: 6.67s\tremaining: 5.28s\n",
            "558:\tlearn: 0.1142672\ttotal: 6.68s\tremaining: 5.27s\n",
            "559:\tlearn: 0.1140834\ttotal: 6.69s\tremaining: 5.25s\n",
            "560:\tlearn: 0.1137749\ttotal: 6.7s\tremaining: 5.24s\n",
            "561:\tlearn: 0.1136049\ttotal: 6.71s\tremaining: 5.23s\n",
            "562:\tlearn: 0.1133588\ttotal: 6.72s\tremaining: 5.22s\n",
            "563:\tlearn: 0.1129640\ttotal: 6.74s\tremaining: 5.21s\n",
            "564:\tlearn: 0.1127539\ttotal: 6.75s\tremaining: 5.19s\n",
            "565:\tlearn: 0.1125086\ttotal: 6.76s\tremaining: 5.18s\n",
            "566:\tlearn: 0.1123582\ttotal: 6.77s\tremaining: 5.17s\n",
            "567:\tlearn: 0.1121066\ttotal: 6.78s\tremaining: 5.16s\n",
            "568:\tlearn: 0.1118309\ttotal: 6.79s\tremaining: 5.14s\n",
            "569:\tlearn: 0.1115647\ttotal: 6.8s\tremaining: 5.13s\n",
            "570:\tlearn: 0.1113690\ttotal: 6.82s\tremaining: 5.13s\n",
            "571:\tlearn: 0.1112269\ttotal: 6.83s\tremaining: 5.11s\n",
            "572:\tlearn: 0.1111008\ttotal: 6.84s\tremaining: 5.1s\n",
            "573:\tlearn: 0.1109924\ttotal: 6.86s\tremaining: 5.09s\n",
            "574:\tlearn: 0.1106721\ttotal: 6.87s\tremaining: 5.08s\n",
            "575:\tlearn: 0.1103501\ttotal: 6.88s\tremaining: 5.06s\n",
            "576:\tlearn: 0.1101520\ttotal: 6.89s\tremaining: 5.05s\n",
            "577:\tlearn: 0.1099678\ttotal: 6.9s\tremaining: 5.04s\n",
            "578:\tlearn: 0.1097054\ttotal: 6.92s\tremaining: 5.03s\n",
            "579:\tlearn: 0.1094543\ttotal: 6.93s\tremaining: 5.01s\n",
            "580:\tlearn: 0.1093425\ttotal: 6.94s\tremaining: 5s\n",
            "581:\tlearn: 0.1092316\ttotal: 6.95s\tremaining: 4.99s\n",
            "582:\tlearn: 0.1089949\ttotal: 6.96s\tremaining: 4.98s\n",
            "583:\tlearn: 0.1087367\ttotal: 6.97s\tremaining: 4.96s\n",
            "584:\tlearn: 0.1085696\ttotal: 6.98s\tremaining: 4.95s\n",
            "585:\tlearn: 0.1083647\ttotal: 6.99s\tremaining: 4.94s\n",
            "586:\tlearn: 0.1081311\ttotal: 7s\tremaining: 4.93s\n",
            "587:\tlearn: 0.1079528\ttotal: 7.02s\tremaining: 4.92s\n",
            "588:\tlearn: 0.1078539\ttotal: 7.03s\tremaining: 4.91s\n",
            "589:\tlearn: 0.1076126\ttotal: 7.04s\tremaining: 4.89s\n",
            "590:\tlearn: 0.1074078\ttotal: 7.05s\tremaining: 4.88s\n",
            "591:\tlearn: 0.1073080\ttotal: 7.06s\tremaining: 4.87s\n",
            "592:\tlearn: 0.1071573\ttotal: 7.08s\tremaining: 4.86s\n",
            "593:\tlearn: 0.1068740\ttotal: 7.09s\tremaining: 4.84s\n",
            "594:\tlearn: 0.1066727\ttotal: 7.1s\tremaining: 4.83s\n",
            "595:\tlearn: 0.1063810\ttotal: 7.11s\tremaining: 4.82s\n",
            "596:\tlearn: 0.1061644\ttotal: 7.12s\tremaining: 4.81s\n",
            "597:\tlearn: 0.1059218\ttotal: 7.13s\tremaining: 4.79s\n",
            "598:\tlearn: 0.1057735\ttotal: 7.14s\tremaining: 4.78s\n",
            "599:\tlearn: 0.1055611\ttotal: 7.16s\tremaining: 4.77s\n",
            "600:\tlearn: 0.1052797\ttotal: 7.17s\tremaining: 4.76s\n",
            "601:\tlearn: 0.1050985\ttotal: 7.18s\tremaining: 4.75s\n",
            "602:\tlearn: 0.1048232\ttotal: 7.19s\tremaining: 4.73s\n",
            "603:\tlearn: 0.1046498\ttotal: 7.2s\tremaining: 4.72s\n",
            "604:\tlearn: 0.1045074\ttotal: 7.21s\tremaining: 4.71s\n",
            "605:\tlearn: 0.1043941\ttotal: 7.23s\tremaining: 4.7s\n",
            "606:\tlearn: 0.1041600\ttotal: 7.24s\tremaining: 4.69s\n",
            "607:\tlearn: 0.1039729\ttotal: 7.25s\tremaining: 4.67s\n",
            "608:\tlearn: 0.1037753\ttotal: 7.26s\tremaining: 4.66s\n",
            "609:\tlearn: 0.1035307\ttotal: 7.27s\tremaining: 4.65s\n",
            "610:\tlearn: 0.1033591\ttotal: 7.29s\tremaining: 4.64s\n",
            "611:\tlearn: 0.1032095\ttotal: 7.3s\tremaining: 4.63s\n",
            "612:\tlearn: 0.1030794\ttotal: 7.31s\tremaining: 4.61s\n",
            "613:\tlearn: 0.1028250\ttotal: 7.32s\tremaining: 4.6s\n",
            "614:\tlearn: 0.1027632\ttotal: 7.33s\tremaining: 4.59s\n",
            "615:\tlearn: 0.1026109\ttotal: 7.34s\tremaining: 4.58s\n",
            "616:\tlearn: 0.1024333\ttotal: 7.35s\tremaining: 4.56s\n",
            "617:\tlearn: 0.1022715\ttotal: 7.36s\tremaining: 4.55s\n",
            "618:\tlearn: 0.1021062\ttotal: 7.38s\tremaining: 4.54s\n",
            "619:\tlearn: 0.1020153\ttotal: 7.39s\tremaining: 4.53s\n",
            "620:\tlearn: 0.1017597\ttotal: 7.4s\tremaining: 4.52s\n",
            "621:\tlearn: 0.1015501\ttotal: 7.42s\tremaining: 4.51s\n",
            "622:\tlearn: 0.1012838\ttotal: 7.43s\tremaining: 4.5s\n",
            "623:\tlearn: 0.1010640\ttotal: 7.44s\tremaining: 4.48s\n",
            "624:\tlearn: 0.1007828\ttotal: 7.45s\tremaining: 4.47s\n",
            "625:\tlearn: 0.1006046\ttotal: 7.46s\tremaining: 4.46s\n",
            "626:\tlearn: 0.1004951\ttotal: 7.48s\tremaining: 4.45s\n",
            "627:\tlearn: 0.1003250\ttotal: 7.49s\tremaining: 4.43s\n",
            "628:\tlearn: 0.1001208\ttotal: 7.5s\tremaining: 4.42s\n",
            "629:\tlearn: 0.0998913\ttotal: 7.51s\tremaining: 4.41s\n",
            "630:\tlearn: 0.0998017\ttotal: 7.52s\tremaining: 4.4s\n",
            "631:\tlearn: 0.0996952\ttotal: 7.53s\tremaining: 4.39s\n",
            "632:\tlearn: 0.0995291\ttotal: 7.54s\tremaining: 4.37s\n",
            "633:\tlearn: 0.0993594\ttotal: 7.56s\tremaining: 4.36s\n",
            "634:\tlearn: 0.0991429\ttotal: 7.57s\tremaining: 4.35s\n",
            "635:\tlearn: 0.0989753\ttotal: 7.59s\tremaining: 4.34s\n",
            "636:\tlearn: 0.0987982\ttotal: 7.6s\tremaining: 4.33s\n",
            "637:\tlearn: 0.0985908\ttotal: 7.61s\tremaining: 4.32s\n",
            "638:\tlearn: 0.0983999\ttotal: 7.63s\tremaining: 4.31s\n",
            "639:\tlearn: 0.0981794\ttotal: 7.64s\tremaining: 4.3s\n",
            "640:\tlearn: 0.0979965\ttotal: 7.66s\tremaining: 4.29s\n",
            "641:\tlearn: 0.0978847\ttotal: 7.67s\tremaining: 4.28s\n",
            "642:\tlearn: 0.0977779\ttotal: 7.68s\tremaining: 4.26s\n",
            "643:\tlearn: 0.0976758\ttotal: 7.69s\tremaining: 4.25s\n",
            "644:\tlearn: 0.0974197\ttotal: 7.7s\tremaining: 4.24s\n",
            "645:\tlearn: 0.0972150\ttotal: 7.71s\tremaining: 4.23s\n",
            "646:\tlearn: 0.0971076\ttotal: 7.72s\tremaining: 4.21s\n",
            "647:\tlearn: 0.0969461\ttotal: 7.73s\tremaining: 4.2s\n",
            "648:\tlearn: 0.0968106\ttotal: 7.74s\tremaining: 4.19s\n",
            "649:\tlearn: 0.0966598\ttotal: 7.75s\tremaining: 4.17s\n",
            "650:\tlearn: 0.0964955\ttotal: 7.76s\tremaining: 4.16s\n",
            "651:\tlearn: 0.0962389\ttotal: 7.77s\tremaining: 4.15s\n",
            "652:\tlearn: 0.0960331\ttotal: 7.79s\tremaining: 4.14s\n",
            "653:\tlearn: 0.0958871\ttotal: 7.8s\tremaining: 4.12s\n",
            "654:\tlearn: 0.0957798\ttotal: 7.81s\tremaining: 4.11s\n",
            "655:\tlearn: 0.0956683\ttotal: 7.82s\tremaining: 4.1s\n",
            "656:\tlearn: 0.0954905\ttotal: 7.83s\tremaining: 4.09s\n",
            "657:\tlearn: 0.0952806\ttotal: 7.85s\tremaining: 4.08s\n",
            "658:\tlearn: 0.0949836\ttotal: 7.86s\tremaining: 4.07s\n",
            "659:\tlearn: 0.0948606\ttotal: 7.87s\tremaining: 4.05s\n",
            "660:\tlearn: 0.0946249\ttotal: 7.88s\tremaining: 4.04s\n",
            "661:\tlearn: 0.0944674\ttotal: 7.9s\tremaining: 4.03s\n",
            "662:\tlearn: 0.0942536\ttotal: 7.91s\tremaining: 4.02s\n",
            "663:\tlearn: 0.0940522\ttotal: 7.92s\tremaining: 4.01s\n",
            "664:\tlearn: 0.0938868\ttotal: 7.93s\tremaining: 4s\n",
            "665:\tlearn: 0.0936758\ttotal: 7.94s\tremaining: 3.98s\n",
            "666:\tlearn: 0.0934427\ttotal: 7.96s\tremaining: 3.97s\n",
            "667:\tlearn: 0.0932527\ttotal: 7.97s\tremaining: 3.96s\n",
            "668:\tlearn: 0.0930922\ttotal: 7.98s\tremaining: 3.95s\n",
            "669:\tlearn: 0.0928655\ttotal: 7.99s\tremaining: 3.94s\n",
            "670:\tlearn: 0.0926503\ttotal: 8s\tremaining: 3.92s\n",
            "671:\tlearn: 0.0925445\ttotal: 8.01s\tremaining: 3.91s\n",
            "672:\tlearn: 0.0924080\ttotal: 8.03s\tremaining: 3.9s\n",
            "673:\tlearn: 0.0922242\ttotal: 8.04s\tremaining: 3.89s\n",
            "674:\tlearn: 0.0919883\ttotal: 8.05s\tremaining: 3.88s\n",
            "675:\tlearn: 0.0918608\ttotal: 8.06s\tremaining: 3.87s\n",
            "676:\tlearn: 0.0916020\ttotal: 8.08s\tremaining: 3.85s\n",
            "677:\tlearn: 0.0914620\ttotal: 8.09s\tremaining: 3.84s\n",
            "678:\tlearn: 0.0912942\ttotal: 8.1s\tremaining: 3.83s\n",
            "679:\tlearn: 0.0911446\ttotal: 8.11s\tremaining: 3.82s\n",
            "680:\tlearn: 0.0909505\ttotal: 8.12s\tremaining: 3.8s\n",
            "681:\tlearn: 0.0907568\ttotal: 8.13s\tremaining: 3.79s\n",
            "682:\tlearn: 0.0906764\ttotal: 8.14s\tremaining: 3.78s\n",
            "683:\tlearn: 0.0905690\ttotal: 8.15s\tremaining: 3.77s\n",
            "684:\tlearn: 0.0904445\ttotal: 8.17s\tremaining: 3.75s\n",
            "685:\tlearn: 0.0903398\ttotal: 8.18s\tremaining: 3.74s\n",
            "686:\tlearn: 0.0902204\ttotal: 8.19s\tremaining: 3.73s\n",
            "687:\tlearn: 0.0901160\ttotal: 8.2s\tremaining: 3.72s\n",
            "688:\tlearn: 0.0898955\ttotal: 8.21s\tremaining: 3.71s\n",
            "689:\tlearn: 0.0897800\ttotal: 8.22s\tremaining: 3.69s\n",
            "690:\tlearn: 0.0896587\ttotal: 8.23s\tremaining: 3.68s\n",
            "691:\tlearn: 0.0894811\ttotal: 8.25s\tremaining: 3.67s\n",
            "692:\tlearn: 0.0893450\ttotal: 8.26s\tremaining: 3.66s\n",
            "693:\tlearn: 0.0892084\ttotal: 8.27s\tremaining: 3.65s\n",
            "694:\tlearn: 0.0890378\ttotal: 8.28s\tremaining: 3.63s\n",
            "695:\tlearn: 0.0888669\ttotal: 8.3s\tremaining: 3.62s\n",
            "696:\tlearn: 0.0886667\ttotal: 8.31s\tremaining: 3.61s\n",
            "697:\tlearn: 0.0885174\ttotal: 8.32s\tremaining: 3.6s\n",
            "698:\tlearn: 0.0884252\ttotal: 8.33s\tremaining: 3.59s\n",
            "699:\tlearn: 0.0882588\ttotal: 8.34s\tremaining: 3.58s\n",
            "700:\tlearn: 0.0881674\ttotal: 8.35s\tremaining: 3.56s\n",
            "701:\tlearn: 0.0880854\ttotal: 8.37s\tremaining: 3.55s\n",
            "702:\tlearn: 0.0879593\ttotal: 8.38s\tremaining: 3.54s\n",
            "703:\tlearn: 0.0878335\ttotal: 8.39s\tremaining: 3.53s\n",
            "704:\tlearn: 0.0876206\ttotal: 8.4s\tremaining: 3.52s\n",
            "705:\tlearn: 0.0875781\ttotal: 8.4s\tremaining: 3.5s\n",
            "706:\tlearn: 0.0874210\ttotal: 8.41s\tremaining: 3.49s\n",
            "707:\tlearn: 0.0873430\ttotal: 8.43s\tremaining: 3.48s\n",
            "708:\tlearn: 0.0871901\ttotal: 8.44s\tremaining: 3.46s\n",
            "709:\tlearn: 0.0870315\ttotal: 8.46s\tremaining: 3.45s\n",
            "710:\tlearn: 0.0868657\ttotal: 8.47s\tremaining: 3.44s\n",
            "711:\tlearn: 0.0866974\ttotal: 8.48s\tremaining: 3.43s\n",
            "712:\tlearn: 0.0865013\ttotal: 8.49s\tremaining: 3.42s\n",
            "713:\tlearn: 0.0864437\ttotal: 8.5s\tremaining: 3.4s\n",
            "714:\tlearn: 0.0862772\ttotal: 8.51s\tremaining: 3.39s\n",
            "715:\tlearn: 0.0861183\ttotal: 8.52s\tremaining: 3.38s\n",
            "716:\tlearn: 0.0859848\ttotal: 8.54s\tremaining: 3.37s\n",
            "717:\tlearn: 0.0858770\ttotal: 8.55s\tremaining: 3.36s\n",
            "718:\tlearn: 0.0857941\ttotal: 8.56s\tremaining: 3.34s\n",
            "719:\tlearn: 0.0857318\ttotal: 8.58s\tremaining: 3.33s\n",
            "720:\tlearn: 0.0855307\ttotal: 8.59s\tremaining: 3.32s\n",
            "721:\tlearn: 0.0853370\ttotal: 8.6s\tremaining: 3.31s\n",
            "722:\tlearn: 0.0852515\ttotal: 8.62s\tremaining: 3.3s\n",
            "723:\tlearn: 0.0850678\ttotal: 8.63s\tremaining: 3.29s\n",
            "724:\tlearn: 0.0849288\ttotal: 8.64s\tremaining: 3.28s\n",
            "725:\tlearn: 0.0847885\ttotal: 8.65s\tremaining: 3.26s\n",
            "726:\tlearn: 0.0846775\ttotal: 8.67s\tremaining: 3.25s\n",
            "727:\tlearn: 0.0844925\ttotal: 8.68s\tremaining: 3.24s\n",
            "728:\tlearn: 0.0844093\ttotal: 8.69s\tremaining: 3.23s\n",
            "729:\tlearn: 0.0842968\ttotal: 8.7s\tremaining: 3.22s\n",
            "730:\tlearn: 0.0841652\ttotal: 8.71s\tremaining: 3.21s\n",
            "731:\tlearn: 0.0840249\ttotal: 8.72s\tremaining: 3.19s\n",
            "732:\tlearn: 0.0839183\ttotal: 8.73s\tremaining: 3.18s\n",
            "733:\tlearn: 0.0838102\ttotal: 8.75s\tremaining: 3.17s\n",
            "734:\tlearn: 0.0836888\ttotal: 8.76s\tremaining: 3.16s\n",
            "735:\tlearn: 0.0836616\ttotal: 8.77s\tremaining: 3.15s\n",
            "736:\tlearn: 0.0835708\ttotal: 8.78s\tremaining: 3.13s\n",
            "737:\tlearn: 0.0833964\ttotal: 8.79s\tremaining: 3.12s\n",
            "738:\tlearn: 0.0832791\ttotal: 8.8s\tremaining: 3.11s\n",
            "739:\tlearn: 0.0830837\ttotal: 8.81s\tremaining: 3.1s\n",
            "740:\tlearn: 0.0829125\ttotal: 8.82s\tremaining: 3.08s\n",
            "741:\tlearn: 0.0827549\ttotal: 8.84s\tremaining: 3.07s\n",
            "742:\tlearn: 0.0826239\ttotal: 8.85s\tremaining: 3.06s\n",
            "743:\tlearn: 0.0824861\ttotal: 8.86s\tremaining: 3.05s\n",
            "744:\tlearn: 0.0823789\ttotal: 8.88s\tremaining: 3.04s\n",
            "745:\tlearn: 0.0822220\ttotal: 8.89s\tremaining: 3.03s\n",
            "746:\tlearn: 0.0820882\ttotal: 8.9s\tremaining: 3.02s\n",
            "747:\tlearn: 0.0819231\ttotal: 8.91s\tremaining: 3s\n",
            "748:\tlearn: 0.0817345\ttotal: 8.93s\tremaining: 2.99s\n",
            "749:\tlearn: 0.0815351\ttotal: 8.94s\tremaining: 2.98s\n",
            "750:\tlearn: 0.0814635\ttotal: 8.95s\tremaining: 2.97s\n",
            "751:\tlearn: 0.0812914\ttotal: 8.96s\tremaining: 2.96s\n",
            "752:\tlearn: 0.0811251\ttotal: 8.97s\tremaining: 2.94s\n",
            "753:\tlearn: 0.0809348\ttotal: 8.98s\tremaining: 2.93s\n",
            "754:\tlearn: 0.0808534\ttotal: 8.99s\tremaining: 2.92s\n",
            "755:\tlearn: 0.0807128\ttotal: 9.01s\tremaining: 2.91s\n",
            "756:\tlearn: 0.0805739\ttotal: 9.02s\tremaining: 2.9s\n",
            "757:\tlearn: 0.0804639\ttotal: 9.03s\tremaining: 2.88s\n",
            "758:\tlearn: 0.0803634\ttotal: 9.04s\tremaining: 2.87s\n",
            "759:\tlearn: 0.0801872\ttotal: 9.05s\tremaining: 2.86s\n",
            "760:\tlearn: 0.0800467\ttotal: 9.06s\tremaining: 2.85s\n",
            "761:\tlearn: 0.0799471\ttotal: 9.08s\tremaining: 2.83s\n",
            "762:\tlearn: 0.0798178\ttotal: 9.09s\tremaining: 2.82s\n",
            "763:\tlearn: 0.0797338\ttotal: 9.1s\tremaining: 2.81s\n",
            "764:\tlearn: 0.0796376\ttotal: 9.11s\tremaining: 2.8s\n",
            "765:\tlearn: 0.0795720\ttotal: 9.13s\tremaining: 2.79s\n",
            "766:\tlearn: 0.0794464\ttotal: 9.14s\tremaining: 2.77s\n",
            "767:\tlearn: 0.0792807\ttotal: 9.15s\tremaining: 2.76s\n",
            "768:\tlearn: 0.0791247\ttotal: 9.16s\tremaining: 2.75s\n",
            "769:\tlearn: 0.0790174\ttotal: 9.17s\tremaining: 2.74s\n",
            "770:\tlearn: 0.0788974\ttotal: 9.18s\tremaining: 2.73s\n",
            "771:\tlearn: 0.0787657\ttotal: 9.19s\tremaining: 2.71s\n",
            "772:\tlearn: 0.0786420\ttotal: 9.21s\tremaining: 2.7s\n",
            "773:\tlearn: 0.0784710\ttotal: 9.22s\tremaining: 2.69s\n",
            "774:\tlearn: 0.0783542\ttotal: 9.23s\tremaining: 2.68s\n",
            "775:\tlearn: 0.0782345\ttotal: 9.24s\tremaining: 2.67s\n",
            "776:\tlearn: 0.0781440\ttotal: 9.25s\tremaining: 2.65s\n",
            "777:\tlearn: 0.0780236\ttotal: 9.26s\tremaining: 2.64s\n",
            "778:\tlearn: 0.0779333\ttotal: 9.27s\tremaining: 2.63s\n",
            "779:\tlearn: 0.0777908\ttotal: 9.29s\tremaining: 2.62s\n",
            "780:\tlearn: 0.0777133\ttotal: 9.3s\tremaining: 2.61s\n",
            "781:\tlearn: 0.0775815\ttotal: 9.32s\tremaining: 2.6s\n",
            "782:\tlearn: 0.0774611\ttotal: 9.33s\tremaining: 2.58s\n",
            "783:\tlearn: 0.0772859\ttotal: 9.34s\tremaining: 2.57s\n",
            "784:\tlearn: 0.0771302\ttotal: 9.35s\tremaining: 2.56s\n",
            "785:\tlearn: 0.0770337\ttotal: 9.37s\tremaining: 2.55s\n",
            "786:\tlearn: 0.0769503\ttotal: 9.38s\tremaining: 2.54s\n",
            "787:\tlearn: 0.0768559\ttotal: 9.39s\tremaining: 2.53s\n",
            "788:\tlearn: 0.0766808\ttotal: 9.4s\tremaining: 2.51s\n",
            "789:\tlearn: 0.0765612\ttotal: 9.41s\tremaining: 2.5s\n",
            "790:\tlearn: 0.0764508\ttotal: 9.43s\tremaining: 2.49s\n",
            "791:\tlearn: 0.0762737\ttotal: 9.44s\tremaining: 2.48s\n",
            "792:\tlearn: 0.0762056\ttotal: 9.45s\tremaining: 2.47s\n",
            "793:\tlearn: 0.0761588\ttotal: 9.46s\tremaining: 2.45s\n",
            "794:\tlearn: 0.0760278\ttotal: 9.47s\tremaining: 2.44s\n",
            "795:\tlearn: 0.0758642\ttotal: 9.48s\tremaining: 2.43s\n",
            "796:\tlearn: 0.0757837\ttotal: 9.5s\tremaining: 2.42s\n",
            "797:\tlearn: 0.0756733\ttotal: 9.51s\tremaining: 2.41s\n",
            "798:\tlearn: 0.0756056\ttotal: 9.52s\tremaining: 2.4s\n",
            "799:\tlearn: 0.0754554\ttotal: 9.53s\tremaining: 2.38s\n",
            "800:\tlearn: 0.0753560\ttotal: 9.54s\tremaining: 2.37s\n",
            "801:\tlearn: 0.0752233\ttotal: 9.56s\tremaining: 2.36s\n",
            "802:\tlearn: 0.0750869\ttotal: 9.57s\tremaining: 2.35s\n",
            "803:\tlearn: 0.0749851\ttotal: 9.59s\tremaining: 2.34s\n",
            "804:\tlearn: 0.0748181\ttotal: 9.6s\tremaining: 2.32s\n",
            "805:\tlearn: 0.0747867\ttotal: 9.61s\tremaining: 2.31s\n",
            "806:\tlearn: 0.0747397\ttotal: 9.61s\tremaining: 2.3s\n",
            "807:\tlearn: 0.0746424\ttotal: 9.62s\tremaining: 2.29s\n",
            "808:\tlearn: 0.0745013\ttotal: 9.63s\tremaining: 2.27s\n",
            "809:\tlearn: 0.0744247\ttotal: 9.65s\tremaining: 2.26s\n",
            "810:\tlearn: 0.0743068\ttotal: 9.66s\tremaining: 2.25s\n",
            "811:\tlearn: 0.0741629\ttotal: 9.67s\tremaining: 2.24s\n",
            "812:\tlearn: 0.0740268\ttotal: 9.68s\tremaining: 2.23s\n",
            "813:\tlearn: 0.0739278\ttotal: 9.7s\tremaining: 2.21s\n",
            "814:\tlearn: 0.0737731\ttotal: 9.71s\tremaining: 2.2s\n",
            "815:\tlearn: 0.0735744\ttotal: 9.73s\tremaining: 2.19s\n",
            "816:\tlearn: 0.0734859\ttotal: 9.74s\tremaining: 2.18s\n",
            "817:\tlearn: 0.0733373\ttotal: 9.76s\tremaining: 2.17s\n",
            "818:\tlearn: 0.0732285\ttotal: 9.77s\tremaining: 2.16s\n",
            "819:\tlearn: 0.0732018\ttotal: 9.77s\tremaining: 2.15s\n",
            "820:\tlearn: 0.0731028\ttotal: 9.78s\tremaining: 2.13s\n",
            "821:\tlearn: 0.0729278\ttotal: 9.79s\tremaining: 2.12s\n",
            "822:\tlearn: 0.0728511\ttotal: 9.81s\tremaining: 2.11s\n",
            "823:\tlearn: 0.0727767\ttotal: 9.82s\tremaining: 2.1s\n",
            "824:\tlearn: 0.0726978\ttotal: 9.83s\tremaining: 2.08s\n",
            "825:\tlearn: 0.0725706\ttotal: 9.84s\tremaining: 2.07s\n",
            "826:\tlearn: 0.0725005\ttotal: 9.85s\tremaining: 2.06s\n",
            "827:\tlearn: 0.0723457\ttotal: 9.86s\tremaining: 2.05s\n",
            "828:\tlearn: 0.0722849\ttotal: 9.88s\tremaining: 2.04s\n",
            "829:\tlearn: 0.0721302\ttotal: 9.89s\tremaining: 2.02s\n",
            "830:\tlearn: 0.0720466\ttotal: 9.9s\tremaining: 2.01s\n",
            "831:\tlearn: 0.0719113\ttotal: 9.92s\tremaining: 2s\n",
            "832:\tlearn: 0.0717523\ttotal: 9.93s\tremaining: 1.99s\n",
            "833:\tlearn: 0.0716542\ttotal: 9.94s\tremaining: 1.98s\n",
            "834:\tlearn: 0.0715387\ttotal: 9.95s\tremaining: 1.97s\n",
            "835:\tlearn: 0.0713833\ttotal: 9.96s\tremaining: 1.95s\n",
            "836:\tlearn: 0.0712588\ttotal: 9.97s\tremaining: 1.94s\n",
            "837:\tlearn: 0.0710969\ttotal: 9.99s\tremaining: 1.93s\n",
            "838:\tlearn: 0.0709893\ttotal: 10s\tremaining: 1.92s\n",
            "839:\tlearn: 0.0708485\ttotal: 10s\tremaining: 1.91s\n",
            "840:\tlearn: 0.0707196\ttotal: 10s\tremaining: 1.9s\n",
            "841:\tlearn: 0.0705814\ttotal: 10s\tremaining: 1.88s\n",
            "842:\tlearn: 0.0703995\ttotal: 10s\tremaining: 1.87s\n",
            "843:\tlearn: 0.0703567\ttotal: 10.1s\tremaining: 1.86s\n",
            "844:\tlearn: 0.0702506\ttotal: 10.1s\tremaining: 1.85s\n",
            "845:\tlearn: 0.0701228\ttotal: 10.1s\tremaining: 1.83s\n",
            "846:\tlearn: 0.0700167\ttotal: 10.1s\tremaining: 1.82s\n",
            "847:\tlearn: 0.0699511\ttotal: 10.1s\tremaining: 1.81s\n",
            "848:\tlearn: 0.0698946\ttotal: 10.1s\tremaining: 1.8s\n",
            "849:\tlearn: 0.0697562\ttotal: 10.1s\tremaining: 1.79s\n",
            "850:\tlearn: 0.0696791\ttotal: 10.1s\tremaining: 1.78s\n",
            "851:\tlearn: 0.0695156\ttotal: 10.2s\tremaining: 1.76s\n",
            "852:\tlearn: 0.0693647\ttotal: 10.2s\tremaining: 1.75s\n",
            "853:\tlearn: 0.0691988\ttotal: 10.2s\tremaining: 1.74s\n",
            "854:\tlearn: 0.0690400\ttotal: 10.2s\tremaining: 1.73s\n",
            "855:\tlearn: 0.0689475\ttotal: 10.2s\tremaining: 1.72s\n",
            "856:\tlearn: 0.0688485\ttotal: 10.2s\tremaining: 1.7s\n",
            "857:\tlearn: 0.0687361\ttotal: 10.2s\tremaining: 1.69s\n",
            "858:\tlearn: 0.0685904\ttotal: 10.2s\tremaining: 1.68s\n",
            "859:\tlearn: 0.0684674\ttotal: 10.3s\tremaining: 1.67s\n",
            "860:\tlearn: 0.0683586\ttotal: 10.3s\tremaining: 1.66s\n",
            "861:\tlearn: 0.0682362\ttotal: 10.3s\tremaining: 1.64s\n",
            "862:\tlearn: 0.0681808\ttotal: 10.3s\tremaining: 1.63s\n",
            "863:\tlearn: 0.0681202\ttotal: 10.3s\tremaining: 1.62s\n",
            "864:\tlearn: 0.0680285\ttotal: 10.3s\tremaining: 1.61s\n",
            "865:\tlearn: 0.0679478\ttotal: 10.3s\tremaining: 1.6s\n",
            "866:\tlearn: 0.0678347\ttotal: 10.3s\tremaining: 1.58s\n",
            "867:\tlearn: 0.0677031\ttotal: 10.3s\tremaining: 1.57s\n",
            "868:\tlearn: 0.0676446\ttotal: 10.4s\tremaining: 1.56s\n",
            "869:\tlearn: 0.0675557\ttotal: 10.4s\tremaining: 1.55s\n",
            "870:\tlearn: 0.0674396\ttotal: 10.4s\tremaining: 1.54s\n",
            "871:\tlearn: 0.0673685\ttotal: 10.4s\tremaining: 1.53s\n",
            "872:\tlearn: 0.0672530\ttotal: 10.4s\tremaining: 1.51s\n",
            "873:\tlearn: 0.0671838\ttotal: 10.4s\tremaining: 1.5s\n",
            "874:\tlearn: 0.0670383\ttotal: 10.4s\tremaining: 1.49s\n",
            "875:\tlearn: 0.0668753\ttotal: 10.4s\tremaining: 1.48s\n",
            "876:\tlearn: 0.0668122\ttotal: 10.5s\tremaining: 1.47s\n",
            "877:\tlearn: 0.0667040\ttotal: 10.5s\tremaining: 1.45s\n",
            "878:\tlearn: 0.0665700\ttotal: 10.5s\tremaining: 1.44s\n",
            "879:\tlearn: 0.0664438\ttotal: 10.5s\tremaining: 1.43s\n",
            "880:\tlearn: 0.0663959\ttotal: 10.5s\tremaining: 1.42s\n",
            "881:\tlearn: 0.0663004\ttotal: 10.5s\tremaining: 1.41s\n",
            "882:\tlearn: 0.0661925\ttotal: 10.5s\tremaining: 1.39s\n",
            "883:\tlearn: 0.0660437\ttotal: 10.5s\tremaining: 1.38s\n",
            "884:\tlearn: 0.0659800\ttotal: 10.5s\tremaining: 1.37s\n",
            "885:\tlearn: 0.0658873\ttotal: 10.6s\tremaining: 1.36s\n",
            "886:\tlearn: 0.0657630\ttotal: 10.6s\tremaining: 1.35s\n",
            "887:\tlearn: 0.0656170\ttotal: 10.6s\tremaining: 1.33s\n",
            "888:\tlearn: 0.0655413\ttotal: 10.6s\tremaining: 1.32s\n",
            "889:\tlearn: 0.0654892\ttotal: 10.6s\tremaining: 1.31s\n",
            "890:\tlearn: 0.0653518\ttotal: 10.6s\tremaining: 1.3s\n",
            "891:\tlearn: 0.0652632\ttotal: 10.6s\tremaining: 1.29s\n",
            "892:\tlearn: 0.0651717\ttotal: 10.6s\tremaining: 1.27s\n",
            "893:\tlearn: 0.0650943\ttotal: 10.7s\tremaining: 1.26s\n",
            "894:\tlearn: 0.0649717\ttotal: 10.7s\tremaining: 1.25s\n",
            "895:\tlearn: 0.0648331\ttotal: 10.7s\tremaining: 1.24s\n",
            "896:\tlearn: 0.0647198\ttotal: 10.7s\tremaining: 1.23s\n",
            "897:\tlearn: 0.0645884\ttotal: 10.7s\tremaining: 1.22s\n",
            "898:\tlearn: 0.0644515\ttotal: 10.7s\tremaining: 1.2s\n",
            "899:\tlearn: 0.0643460\ttotal: 10.7s\tremaining: 1.19s\n",
            "900:\tlearn: 0.0642586\ttotal: 10.7s\tremaining: 1.18s\n",
            "901:\tlearn: 0.0641378\ttotal: 10.8s\tremaining: 1.17s\n",
            "902:\tlearn: 0.0640376\ttotal: 10.8s\tremaining: 1.16s\n",
            "903:\tlearn: 0.0639083\ttotal: 10.8s\tremaining: 1.15s\n",
            "904:\tlearn: 0.0638178\ttotal: 10.8s\tremaining: 1.13s\n",
            "905:\tlearn: 0.0636470\ttotal: 10.8s\tremaining: 1.12s\n",
            "906:\tlearn: 0.0635448\ttotal: 10.8s\tremaining: 1.11s\n",
            "907:\tlearn: 0.0634150\ttotal: 10.8s\tremaining: 1.1s\n",
            "908:\tlearn: 0.0633060\ttotal: 10.8s\tremaining: 1.08s\n",
            "909:\tlearn: 0.0632069\ttotal: 10.9s\tremaining: 1.07s\n",
            "910:\tlearn: 0.0631500\ttotal: 10.9s\tremaining: 1.06s\n",
            "911:\tlearn: 0.0630675\ttotal: 10.9s\tremaining: 1.05s\n",
            "912:\tlearn: 0.0629619\ttotal: 10.9s\tremaining: 1.04s\n",
            "913:\tlearn: 0.0628694\ttotal: 10.9s\tremaining: 1.02s\n",
            "914:\tlearn: 0.0627634\ttotal: 10.9s\tremaining: 1.01s\n",
            "915:\tlearn: 0.0626935\ttotal: 10.9s\tremaining: 1s\n",
            "916:\tlearn: 0.0625870\ttotal: 10.9s\tremaining: 989ms\n",
            "917:\tlearn: 0.0625436\ttotal: 10.9s\tremaining: 978ms\n",
            "918:\tlearn: 0.0624853\ttotal: 11s\tremaining: 966ms\n",
            "919:\tlearn: 0.0623747\ttotal: 11s\tremaining: 954ms\n",
            "920:\tlearn: 0.0623113\ttotal: 11s\tremaining: 942ms\n",
            "921:\tlearn: 0.0621545\ttotal: 11s\tremaining: 930ms\n",
            "922:\tlearn: 0.0620775\ttotal: 11s\tremaining: 918ms\n",
            "923:\tlearn: 0.0619687\ttotal: 11s\tremaining: 906ms\n",
            "924:\tlearn: 0.0618351\ttotal: 11s\tremaining: 894ms\n",
            "925:\tlearn: 0.0617117\ttotal: 11s\tremaining: 882ms\n",
            "926:\tlearn: 0.0616201\ttotal: 11.1s\tremaining: 870ms\n",
            "927:\tlearn: 0.0615015\ttotal: 11.1s\tremaining: 859ms\n",
            "928:\tlearn: 0.0614367\ttotal: 11.1s\tremaining: 847ms\n",
            "929:\tlearn: 0.0613486\ttotal: 11.1s\tremaining: 835ms\n",
            "930:\tlearn: 0.0612655\ttotal: 11.1s\tremaining: 823ms\n",
            "931:\tlearn: 0.0612104\ttotal: 11.1s\tremaining: 811ms\n",
            "932:\tlearn: 0.0610638\ttotal: 11.1s\tremaining: 799ms\n",
            "933:\tlearn: 0.0609737\ttotal: 11.1s\tremaining: 787ms\n",
            "934:\tlearn: 0.0608540\ttotal: 11.1s\tremaining: 775ms\n",
            "935:\tlearn: 0.0607012\ttotal: 11.2s\tremaining: 763ms\n",
            "936:\tlearn: 0.0605667\ttotal: 11.2s\tremaining: 751ms\n",
            "937:\tlearn: 0.0604373\ttotal: 11.2s\tremaining: 739ms\n",
            "938:\tlearn: 0.0603816\ttotal: 11.2s\tremaining: 727ms\n",
            "939:\tlearn: 0.0602419\ttotal: 11.2s\tremaining: 715ms\n",
            "940:\tlearn: 0.0601651\ttotal: 11.2s\tremaining: 703ms\n",
            "941:\tlearn: 0.0600145\ttotal: 11.2s\tremaining: 691ms\n",
            "942:\tlearn: 0.0599109\ttotal: 11.2s\tremaining: 679ms\n",
            "943:\tlearn: 0.0598663\ttotal: 11.3s\tremaining: 667ms\n",
            "944:\tlearn: 0.0597440\ttotal: 11.3s\tremaining: 656ms\n",
            "945:\tlearn: 0.0596452\ttotal: 11.3s\tremaining: 644ms\n",
            "946:\tlearn: 0.0595750\ttotal: 11.3s\tremaining: 632ms\n",
            "947:\tlearn: 0.0594453\ttotal: 11.3s\tremaining: 620ms\n",
            "948:\tlearn: 0.0593211\ttotal: 11.3s\tremaining: 608ms\n",
            "949:\tlearn: 0.0592146\ttotal: 11.3s\tremaining: 596ms\n",
            "950:\tlearn: 0.0591425\ttotal: 11.3s\tremaining: 584ms\n",
            "951:\tlearn: 0.0591012\ttotal: 11.4s\tremaining: 572ms\n",
            "952:\tlearn: 0.0590177\ttotal: 11.4s\tremaining: 561ms\n",
            "953:\tlearn: 0.0589457\ttotal: 11.4s\tremaining: 549ms\n",
            "954:\tlearn: 0.0588785\ttotal: 11.4s\tremaining: 537ms\n",
            "955:\tlearn: 0.0587471\ttotal: 11.4s\tremaining: 525ms\n",
            "956:\tlearn: 0.0586998\ttotal: 11.4s\tremaining: 513ms\n",
            "957:\tlearn: 0.0586388\ttotal: 11.4s\tremaining: 501ms\n",
            "958:\tlearn: 0.0585315\ttotal: 11.4s\tremaining: 489ms\n",
            "959:\tlearn: 0.0584414\ttotal: 11.5s\tremaining: 477ms\n",
            "960:\tlearn: 0.0583255\ttotal: 11.5s\tremaining: 466ms\n",
            "961:\tlearn: 0.0582833\ttotal: 11.5s\tremaining: 454ms\n",
            "962:\tlearn: 0.0582138\ttotal: 11.5s\tremaining: 442ms\n",
            "963:\tlearn: 0.0581596\ttotal: 11.5s\tremaining: 430ms\n",
            "964:\tlearn: 0.0580483\ttotal: 11.5s\tremaining: 418ms\n",
            "965:\tlearn: 0.0579592\ttotal: 11.5s\tremaining: 406ms\n",
            "966:\tlearn: 0.0579096\ttotal: 11.5s\tremaining: 394ms\n",
            "967:\tlearn: 0.0578004\ttotal: 11.6s\tremaining: 382ms\n",
            "968:\tlearn: 0.0576991\ttotal: 11.6s\tremaining: 370ms\n",
            "969:\tlearn: 0.0576159\ttotal: 11.6s\tremaining: 359ms\n",
            "970:\tlearn: 0.0575742\ttotal: 11.6s\tremaining: 347ms\n",
            "971:\tlearn: 0.0574984\ttotal: 11.6s\tremaining: 335ms\n",
            "972:\tlearn: 0.0574073\ttotal: 11.6s\tremaining: 323ms\n",
            "973:\tlearn: 0.0573425\ttotal: 11.6s\tremaining: 311ms\n",
            "974:\tlearn: 0.0573091\ttotal: 11.7s\tremaining: 299ms\n",
            "975:\tlearn: 0.0572862\ttotal: 11.7s\tremaining: 287ms\n",
            "976:\tlearn: 0.0572318\ttotal: 11.7s\tremaining: 275ms\n",
            "977:\tlearn: 0.0571161\ttotal: 11.7s\tremaining: 263ms\n",
            "978:\tlearn: 0.0570000\ttotal: 11.7s\tremaining: 251ms\n",
            "979:\tlearn: 0.0568887\ttotal: 11.7s\tremaining: 239ms\n",
            "980:\tlearn: 0.0567875\ttotal: 11.7s\tremaining: 227ms\n",
            "981:\tlearn: 0.0567435\ttotal: 11.7s\tremaining: 215ms\n",
            "982:\tlearn: 0.0566719\ttotal: 11.7s\tremaining: 203ms\n",
            "983:\tlearn: 0.0565922\ttotal: 11.8s\tremaining: 191ms\n",
            "984:\tlearn: 0.0565388\ttotal: 11.8s\tremaining: 179ms\n",
            "985:\tlearn: 0.0564427\ttotal: 11.8s\tremaining: 167ms\n",
            "986:\tlearn: 0.0564035\ttotal: 11.8s\tremaining: 155ms\n",
            "987:\tlearn: 0.0563406\ttotal: 11.8s\tremaining: 143ms\n",
            "988:\tlearn: 0.0562530\ttotal: 11.8s\tremaining: 131ms\n",
            "989:\tlearn: 0.0561593\ttotal: 11.8s\tremaining: 119ms\n",
            "990:\tlearn: 0.0560904\ttotal: 11.8s\tremaining: 107ms\n",
            "991:\tlearn: 0.0560027\ttotal: 11.8s\tremaining: 95.5ms\n",
            "992:\tlearn: 0.0558883\ttotal: 11.9s\tremaining: 83.6ms\n",
            "993:\tlearn: 0.0557914\ttotal: 11.9s\tremaining: 71.6ms\n",
            "994:\tlearn: 0.0557021\ttotal: 11.9s\tremaining: 59.7ms\n",
            "995:\tlearn: 0.0556410\ttotal: 11.9s\tremaining: 47.8ms\n",
            "996:\tlearn: 0.0555749\ttotal: 11.9s\tremaining: 35.8ms\n",
            "997:\tlearn: 0.0554968\ttotal: 11.9s\tremaining: 23.9ms\n",
            "998:\tlearn: 0.0554503\ttotal: 11.9s\tremaining: 11.9ms\n",
            "999:\tlearn: 0.0553976\ttotal: 11.9s\tremaining: 0us\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GtH5y8VL-Ol"
      },
      "source": [
        "print(f'The f1_score of train is {np.round(f1_score(y_train,model_cat_train)*100)}% and the f1_score of test is {np.round(f1_score(y_test,model_cat_test)*100,2)}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjnhUmoVMHIV"
      },
      "source": [
        "results['algorithm'].append('CatBoost')\n",
        "results['train score'].append(np.round(f1_score(y_train,model_cat_train)*100))\n",
        "results['test score'].append(np.round(f1_score(y_test,model_cat_test)*100,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elSNuU3s6kNm"
      },
      "source": [
        "# Now We'll apply two types of artificial neural networks, a basic type: Perceptron and a more advanced type: Multi-layer Perceptron."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spJHoXVM6gPZ"
      },
      "source": [
        "## `Perceptron`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruV7IbiG7-81"
      },
      "source": [
        "model_ann_perceptron = Perceptron(max_iter = 400, random_state = 42, n_jobs = -1, early_stopping = True, penalty = 'l2', eta0 = 000.1).fit(X_train, y_train)\n",
        "model_ann_perceptron"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Vl9m0BE89Hc"
      },
      "source": [
        "model_ann_perceptron_train = model_ann_perceptron.predict(X_train)\n",
        "model_ann_perceptron_test = model_ann_perceptron.predict(X_test)\n",
        "print(f'The f1_score of train is {np.round(f1_score(y_train,model_ann_perceptron_train)*100)}% and the f1_score of test is {np.round(f1_score(y_test,model_ann_perceptron_test)*100,2)}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMfEuo-cE760"
      },
      "source": [
        "results['algorithm'].append('Perceptron')\n",
        "results['train score'].append(np.round(f1_score(y_train,model_ann_perceptron_train)*100))\n",
        "results['test score'].append(np.round(f1_score(y_test,model_ann_perceptron_test)*100,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdcKfJv7AMWj"
      },
      "source": [
        "## `Multi-layer Perceptron`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVeRPafLBO94"
      },
      "source": [
        "model_ann_MULperceptron = MLPClassifier(hidden_layer_sizes = 100 ,n_iter_no_change = 100, early_stopping = True, random_state = 42, activation='relu').fit(X_train, y_train)\n",
        "model_ann_MULperceptron"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An9x7SNTmuVU",
        "outputId": "94f8aaf9-5494-41a7-f659-2ef9fe282746"
      },
      "source": [
        "model_ann_MULperceptron.loss_"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4616850701938193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjudmgBwBoT2"
      },
      "source": [
        "model_ann_MULperceptron_train = model_ann_MULperceptron.predict(X_train)\n",
        "model_ann_MULperceptron_test = model_ann_MULperceptron.predict(X_test)\n",
        "print(f'The f1_score of train is {np.round(f1_score(y_train,model_ann_MULperceptron_train)*100)}% and the f1_score of test is {np.round(f1_score(y_test,model_ann_MULperceptron_test)*100,2)}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goX30LwQFHGz"
      },
      "source": [
        "results['algorithm'].append('Multi-Layer Perceptron')\n",
        "results['train score'].append(np.round(f1_score(y_train,model_ann_MULperceptron_train)*100))\n",
        "results['test score'].append(np.round(f1_score(y_test,model_ann_MULperceptron_test)*100,2))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vKa7-CvDndb"
      },
      "source": [
        "# Table of results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "xjVl9NCkDqPn",
        "outputId": "02ca510e-216c-4398-f1af-a23478953a99"
      },
      "source": [
        "pd.DataFrame.from_dict(results)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>algorithm</th>\n",
              "      <th>train score</th>\n",
              "      <th>test score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>76.37</td>\n",
              "      <td>70.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gradient Bosting</td>\n",
              "      <td>100.00</td>\n",
              "      <td>62.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>100.00</td>\n",
              "      <td>67.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LGBM</td>\n",
              "      <td>100.00</td>\n",
              "      <td>65.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>100.00</td>\n",
              "      <td>64.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Perceptron</td>\n",
              "      <td>55.00</td>\n",
              "      <td>57.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Multi-Layer Perceptron</td>\n",
              "      <td>68.00</td>\n",
              "      <td>55.71</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                algorithm  train score  test score\n",
              "0           Random Forest        76.37       70.00\n",
              "1        Gradient Bosting       100.00       62.94\n",
              "2                 XGBoost       100.00       67.63\n",
              "3                    LGBM       100.00       65.28\n",
              "4                CatBoost       100.00       64.29\n",
              "5              Perceptron        55.00       57.47\n",
              "6  Multi-Layer Perceptron        68.00       55.71"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>algorithm</th>\n",
              "      <th>train score</th>\n",
              "      <th>test score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>76.37</td>\n",
              "      <td>70.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gradient Bosting</td>\n",
              "      <td>100.00</td>\n",
              "      <td>62.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>100.00</td>\n",
              "      <td>67.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LGBM</td>\n",
              "      <td>100.00</td>\n",
              "      <td>65.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>100.00</td>\n",
              "      <td>64.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Perceptron</td>\n",
              "      <td>55.00</td>\n",
              "      <td>57.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Multi-Layer Perceptron</td>\n",
              "      <td>68.00</td>\n",
              "      <td>55.71</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                algorithm  train score  test score\n",
              "0           Random Forest        76.37       70.00\n",
              "1        Gradient Bosting       100.00       62.94\n",
              "2                 XGBoost       100.00       67.63\n",
              "3                    LGBM       100.00       65.28\n",
              "4                CatBoost       100.00       64.29\n",
              "5              Perceptron        55.00       57.47\n",
              "6  Multi-Layer Perceptron        68.00       55.71"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2W8PpcpG9K1"
      },
      "source": [
        "## A unique problem was that the results are duplicated, just it..."
      ]
    }
  ]
}
